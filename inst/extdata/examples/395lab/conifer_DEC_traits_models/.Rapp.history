exp(-34.5)
exp()
exp(1)
34.5-20.9
exp(13.6#
)
exp(-20.9) / 1.039538e-15
restable2 = restable#
#
# With AICs:#
AICtable = calc_AIC_column(LnL_vals=restable$LnL, nparam_vals=restable$numparams)#
restable = cbind(restable, AICtable)#
restable_AIC_rellike = AkaikeWeights_on_summary_table(restable=restable, colname_to_use="AIC")#
restable_AIC_rellike = put_jcol_after_ecol(restable_AIC_rellike)#
restable_AIC_rellike#
#
# With AICcs -- factors in sample size#
samplesize = length(tr$tip.label)#
AICtable = calc_AICc_column(LnL_vals=restable$LnL, nparam_vals=restable$numparams, samplesize=samplesize)#
restable2 = cbind(restable2, AICtable)#
restable_AICc_rellike = AkaikeWeights_on_summary_table(restable=restable2, colname_to_use="AICc")#
restable_AICc_rellike = put_jcol_after_ecol(restable_AICc_rellike)#
restable_AICc_rellike
restable = NULL#
teststable = NULL#
#
########################################################
# Statistics -- DEC vs. DEC+J#
########################################################
# We have to extract the log-likelihood differently, depending on the #
# version of optim/optimx#
LnL_2 = get_LnL_from_BioGeoBEARS_results_object(resDEC)#
LnL_1 = get_LnL_from_BioGeoBEARS_results_object(resDECj)#
#
numparams1 = 3#
numparams2 = 2#
stats = AICstats_2models(LnL_1, LnL_2, numparams1, numparams2)#
stats#
#
# DEC, null model for Likelihood Ratio Test (LRT)#
res2 = extract_params_from_BioGeoBEARS_results_object(results_object=resDEC, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
# DEC+J, alternative model for Likelihood Ratio Test (LRT)#
res1 = extract_params_from_BioGeoBEARS_results_object(results_object=resDECj, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
#
# The null hypothesis for a Likelihood Ratio Test (LRT) is that two models#
# confer the same likelihood on the data. See: Brian O'Meara's webpage:#
# http://www.brianomeara.info/tutorials/aic#
# ...for an intro to LRT, AIC, and AICc#
#
rbind(res2, res1)#
tmp_tests = conditional_format_table(stats)#
#
restable = rbind(restable, res2, res1)#
teststable = rbind(teststable, tmp_tests)#
#
########################################################
# Statistics -- DIVALIKE vs. DIVALIKE+J#
########################################################
# We have to extract the log-likelihood differently, depending on the #
# version of optim/optimx#
LnL_2 = get_LnL_from_BioGeoBEARS_results_object(resDIVALIKE)#
LnL_1 = get_LnL_from_BioGeoBEARS_results_object(resDIVALIKEj)#
#
numparams1 = 3#
numparams2 = 2#
stats = AICstats_2models(LnL_1, LnL_2, numparams1, numparams2)#
stats#
#
# DIVALIKE, null model for Likelihood Ratio Test (LRT)#
res2 = extract_params_from_BioGeoBEARS_results_object(results_object=resDIVALIKE, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
# DIVALIKE+J, alternative model for Likelihood Ratio Test (LRT)#
res1 = extract_params_from_BioGeoBEARS_results_object(results_object=resDIVALIKEj, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
#
rbind(res2, res1)#
conditional_format_table(stats)#
#
tmp_tests = conditional_format_table(stats)#
#
restable = rbind(restable, res2, res1)#
teststable = rbind(teststable, tmp_tests)#
#
########################################################
# Statistics -- BAYAREALIKE vs. BAYAREALIKE+J#
########################################################
# We have to extract the log-likelihood differently, depending on the #
# version of optim/optimx#
LnL_2 = get_LnL_from_BioGeoBEARS_results_object(resBAYAREALIKE)#
LnL_1 = get_LnL_from_BioGeoBEARS_results_object(resBAYAREALIKEj)#
#
numparams1 = 3#
numparams2 = 2#
stats = AICstats_2models(LnL_1, LnL_2, numparams1, numparams2)#
stats#
#
# BAYAREALIKE, null model for Likelihood Ratio Test (LRT)#
res2 = extract_params_from_BioGeoBEARS_results_object(results_object=resBAYAREALIKE, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
# BAYAREALIKE+J, alternative model for Likelihood Ratio Test (LRT)#
res1 = extract_params_from_BioGeoBEARS_results_object(results_object=resBAYAREALIKEj, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
#
rbind(res2, res1)#
conditional_format_table(stats)#
#
tmp_tests = conditional_format_table(stats)#
#
restable = rbind(restable, res2, res1)#
teststable = rbind(teststable, tmp_tests)#
#
##########################################################################
# ASSEMBLE RESULTS TABLES: DEC, DEC+J, DIVALIKE, DIVALIKE+J, BAYAREALIKE, BAYAREALIKE+J#
##########################################################################
teststable$alt = c("DEC+J", "DIVALIKE+J", "BAYAREALIKE+J")#
teststable$null = c("DEC", "DIVALIKE", "BAYAREALIKE")#
row.names(restable) = c("DEC", "DEC+J", "DIVALIKE", "DIVALIKE+J", "BAYAREALIKE", "BAYAREALIKE+J")#
restable = put_jcol_after_ecol(restable)#
restable#
#
# Look at the results!!#
restable#
teststable#
#
########################################################
# Save the results tables for later -- check for e.g.#
# convergence issues#
########################################################
#
# Loads to "restable"#
# save(restable, file="restable_v1.Rdata")#
# load(file="restable_v1.Rdata")#
#
# Loads to "teststable"#
# save(teststable, file="teststable_v1.Rdata")#
# load(file="teststable_v1.Rdata")#
#
# Also save to text files#
# write.table(restable, file="restable.txt", quote=FALSE, sep="\t")#
# write.table(unlist_df(teststable), file="teststable.txt", quote=FALSE, sep="\t")#
#
########################################################
# Model weights of all six models#
########################################################
restable2 = restable#
#
# With AICs:#
AICtable = calc_AIC_column(LnL_vals=restable$LnL, nparam_vals=restable$numparams)#
restable = cbind(restable, AICtable)#
restable_AIC_rellike = AkaikeWeights_on_summary_table(restable=restable, colname_to_use="AIC")#
restable_AIC_rellike = put_jcol_after_ecol(restable_AIC_rellike)#
restable_AIC_rellike#
#
# With AICcs -- factors in sample size#
samplesize = length(tr$tip.label)#
AICtable = calc_AICc_column(LnL_vals=restable$LnL, nparam_vals=restable$numparams, samplesize=samplesize)#
restable2 = cbind(restable2, AICtable)#
restable_AICc_rellike = AkaikeWeights_on_summary_table(restable=restable2, colname_to_use="AICc")#
restable_AICc_rellike = put_jcol_after_ecol(restable_AICc_rellike)#
restable_AICc_rellike
conditional_format_table(stats)
library(ape)
?dist.topo
31*31
install.packages("swirl")
library("swirl")
swirl()
5+7
x <- 5 + 7
5385.53/2
3924.43
3924.43-425
########################################################
# This is an introductory example script for the #
# R package "BioGeoBEARS" by Nick Matzke#
# #
# All scripts are copyright Nicholas J. Matzke, #
# please cite if you use. License: GPL-3#
# http://cran.r-project.org/web/licenses/GPL-3#
# #
# I am happy to answer questions at matzke@nimbios.org, but#
# I am more happy to answer questions on the #
# BioGeoBEARS google group#
##
# The package is designed for ML and Bayesian inference#
# of #
# #
# (a) ancestral geographic ranges, and #
# #
# (b) perhaps more importantly, models for the #
#     evolution of geographic range across a phylogeny.#
##
# The example below implements and compares:#
# #
# (1) The standard 2-parameter DEC model implemented in #
#     the program LAGRANGE (Ree & Smith 2008); users will#
#     notice that the ML parameter inference and log-#
#     likelihoods are identical#
##
# (2) A DEC+J model implemented in BioGeoBEARS, wherein#
#     a third parameter, j, is added, representing the #
#     relative per-event weight of founder-event / jump#
#     speciation events at cladogenesis events.  The #
#     higher j is, the more probability these events have,#
#     and the less probability the standard LAGRANGE#
#     cladogenesis events have.#
##
# (3) Some standard model-testing (LRT and AIC) is #
#     implemented at the end so that users may compare models#
##
# (4) The script does similar tests of a DIVA-like model (Ronquist 1997)#
#     and a BAYAREA-like model (Landis, Matzke, Moore, & Huelsenbeck, 2013)#
# #
########################################################
#
########################################################
# Installing BioGeoBEARS#
########################################################
# Uncomment this command to get everything#
# Please use the "0-cloud" R repository at "http://cran.rstudio.com" as it is #
# the only one that keeps download statistics#
########################################################
##
##
# # Install BioGeoBEARS from CRAN 0-cloud:#
# install.packages("BioGeoBEARS", dependencies=TRUE, repos="http://cran.rstudio.com")#
##
########################################################
#
########################################################
# SETUP -- libraries/BioGeoBEARS updates#
########################################################
#
# Load the package (after installation, see above).#
library(GenSA)    # GenSA is better than optimx (although somewhat slower)#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
#
########################################################
# 2018-10-10 update: I have been putting the #
# updates on CRAN/GitHub#
# You should use:#
# rexpokit version 0.26.6 from CRAN#
# cladoRcpp version 0.15 from CRAN#
# BioGeoBEARS version 1.1 from GitHub, install with:#
# library(devtools)#
# devtools::install_github(repo="nmatzke/BioGeoBEARS")#
########################################################
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
########################################################
# CUT: The old instructions to source() online upgrade .R files have been deleted,#
#         all updates are now on the GitHub version of the package, version 1.1+#
########################################################
#
########################################################
# (This local-sourcing is mostly useful for Nick, while actively developing)#
# Local source()-ing method -- uses BioGeoBEARS sourceall() function #
# on a directory of .R files, so you don't have to type them out.#
# The directories here are on my machine, you would have to make a #
# directory, save the .R files there, and refer to them.#
##
# NOTE: it's best to source the "cladoRcpp.R" update first, to avoid warnings like this:#
###
## Note: possible error in 'rcpp_calc_anclikes_sp_COOweights_faster(Rcpp_leftprobs = tmpca_1, ': #
##         unused arguments (m = m, m_null_range = include_null_range, jts_matrix = jts_matrix) #
###
##
# TO USE: Delete or comment out the 'source("http://...")' commands above, and un-comment#
#              the below...#
#########################################################################
# Un-comment (and fix directory paths) to use:#
#library(BioGeoBEARS)#
#source("/drives/Dropbox/_njm/__packages/cladoRcpp_setup/cladoRcpp.R")#
#sourceall("/drives/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#calc_loglike_sp = compiler::cmpfun(calc_loglike_sp_prebyte)    # crucial to fix bug in uppass calculations#
#calc_independent_likelihoods_on_each_branch = compiler::cmpfun(calc_independent_likelihoods_on_each_branch_prebyte)#
#########################################################################
#
########################################################
# SETUP: YOUR WORKING DIRECTORY#
########################################################
# You will need to set your working directory to match your local system#
#
# Note these very handy functions!#
# Command "setwd(x)" sets your working directory#
# Command "getwd()" gets your working directory and tells you what it is.#
# Command "list.files()" lists the files in your working directory#
# To get help on any command, use "?".  E.g., "?list.files"#
#
# Set your working directory for output files#
# default here is your home directory ("~")#
# Change this as you like#
wd = np("~")#
setwd(wd)#
#
# Double-check your working directory with getwd()#
getwd()#
#
########################################################
# SETUP: Extension data directory#
########################################################
# When R packages contain extra files, they are stored in the "extdata" directory #
# inside the installed package.#
##
# BioGeoBEARS contains various example files and scripts in its extdata directory.#
# #
# Each computer operating system might install BioGeoBEARS in a different place, #
# depending on your OS and settings. #
# #
# However, you can find the extdata directory like this:#
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny (plots to a PDF, which avoids issues with multiple graphics in same window):#
pdffn = "tree.pdf"#
pdf(file=pdffn, width=9, height=12)#
#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)#
#
########################################################
# Geography file#
# Notes:#
# 1. This is a PHYLIP-formatted file. This means that in the #
#    first line, #
#    - the 1st number equals the number of rows (species)#
#    - the 2nd number equals the number of columns (number of areas)#
#    - after a tab, put the areas in parentheses, with spaces: (A B C D)#
##
# 1.5. Example first line:#
#    10    4    (A B C D)#
# #
# 2. The second line, and subsequent lines:#
#    speciesA    0110#
#    speciesB    0111#
#    speciesC    0001#
#         ...#
# #
# 2.5a. This means a TAB between the species name and the area 0/1s#
# 2.5b. This also means NO SPACE AND NO TAB between the area 0/1s.#
# #
# 3. See example files at:#
#    http://phylo.wikidot.com/biogeobears#files#
# #
# 4. Make you understand what a PLAIN-TEXT EDITOR is:#
#    http://phylo.wikidot.com/biogeobears#texteditors#
##
# 3. The PHYLIP format is the same format used for C++ LAGRANGE geography files.#
##
# 4. All names in the geography file must match names in the phylogeny file.#
##
# 5. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
##
# 6. Operational taxonomic units (OTUs) should ideally be phylogenetic lineages, #
#    i.e. genetically isolated populations.  These may or may not be identical #
#    with species.  You would NOT want to just use specimens, as each specimen #
#    automatically can only live in 1 area, which will typically favor DEC+J #
#    models.  This is fine if the species/lineages really do live in single areas,#
#    but you wouldn't want to assume this without thinking about it at least. #
#    In summary, you should collapse multiple specimens into species/lineages if #
#    data indicates they are the same genetic population.#
#######################################################
#
# This is the example geography file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))
extdata
extdata_dir
########################################################
# Introduction to Historical Biogeography in R#
# RStudio Cloud tutorial#
##
# 2020-11-06#
# by Nick Matzke#
##
# This tutorial is designed to be run on RStudio Cloud,#
# a free service that runs RStudio through your#
# web browser. You will need to register an RStudio Cloud#
# account (e.g. via gmail). #
##
# Go to:#
# https://rstudio.cloud/#
##
# #
# You should be able to run the following script by#
# cutting-and-pasting the below code.#
##
# Any line that starts with a "#" is a comment. These#
# lines can be pasted, or not -- it doesn't matter,#
# as commented lines are not run by R.#
##
# Please send questions to me on Zoom!#
# #
########################################################
########################################################
# This is an introductory example script for the #
# R package "BioGeoBEARS" by Nick Matzke#
# #
# All scripts are copyright Nicholas J. Matzke, #
# please cite if you use. License: GPL-3#
# http://cran.r-project.org/web/licenses/GPL-3#
# #
# I am happy to answer questions at matzke@nimbios.org, but#
# I am more happy to answer questions on the #
# BioGeoBEARS google group#
##
# The package is designed for ML and Bayesian inference#
# of #
# #
# (a) ancestral geographic ranges, and #
# #
# (b) perhaps more importantly, models for the #
#     evolution of geographic range across a phylogeny.#
##
# The example below implements and compares:#
# #
# (1) The standard 2-parameter DEC model implemented in #
#     the program LAGRANGE (Ree & Smith 2008); users will#
#     notice that the ML parameter inference and log-#
#     likelihoods are identical#
##
# (2) A DEC+J model implemented in BioGeoBEARS, wherein#
#     a third parameter, j, is added, representing the #
#     relative per-event weight of founder-event / jump#
#     speciation events at cladogenesis events.  The #
#     higher j is, the more probability these events have,#
#     and the less probability the standard LAGRANGE#
#     cladogenesis events have.#
##
# (3) Some standard model-testing (LRT and AIC) is #
#     implemented at the end so that users may compare models#
##
# (4) The script does similar tests of a DIVA-like model (Ronquist 1997)#
#     and a BAYAREA-like model (Landis, Matzke, Moore, & Huelsenbeck, 2013)#
# #
########################################################
########################################################
# SETUP -- libraries/BioGeoBEARS dependencies#
########################################################
# install.packages("GenSA")#
# install.packages("FD")#
# install.packages("snow")#
# install.packages("rexpokit")#
# install.packages("cladoRcpp")#
# install.packages("devtools")#
# Load the packages (after installation, see above).#
library(GenSA)    # GenSA is better than optimx (although somewhat slower)#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
library(rexpokit)#
library(cladoRcpp)#
########################################################
# Installing BioGeoBEARS from scratch#
# 2018-10-10 update: I have been putting the #
# updates on CRAN/GitHub#
# You should use:#
# rexpokit version 0.26.6 from CRAN#
# cladoRcpp version 0.15 from CRAN#
# BioGeoBEARS version 1.1 from GitHub, install with:#
library(devtools)#
# devtools::install_github(repo="nmatzke/BioGeoBEARS")#
########################################################
########################################################
########################################################
# #
# #
# As it is easier to maintain#
##
# # Install BioGeoBEARS from CRAN 0-cloud:#
# install.packages("BioGeoBEARS", dependencies=TRUE, repos="http://cran.rstudio.com")#
##
########################################################
library(BioGeoBEARS)#
########################################################
# SETUP: YOUR WORKING DIRECTORY#
########################################################
# You will need to set your working directory to match your local system#
#
# Note these very handy functions!#
# Command "setwd(x)" sets your working directory#
# Command "getwd()" gets your working directory and tells you what it is.#
# Command "list.files()" lists the files in your working directory#
# To get help on any command, use "?".  E.g., "?list.files"#
#
# Set your working directory for output files#
# default here is your home directory ("~")#
# Change this as you like#
wd = np("~")#
setwd(wd)#
#
# Double-check your working directory with getwd()#
getwd()#
#
########################################################
# SETUP: Extension data directory#
########################################################
# When R packages contain extra files, they are stored in the "extdata" directory #
# inside the installed package.#
##
# BioGeoBEARS contains various example files and scripts in its extdata directory.#
# #
# Each computer operating system might install BioGeoBEARS in a different place, #
# depending on your OS and settings. #
# #
# However, you can find the extdata directory like this:#
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny (plots to a PDF, which avoids issues with multiple graphics in same window):#
pdffn = "tree.pdf"#
pdf(file=pdffn, width=9, height=12)#
#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))#
#
# Look at the raw geography text file:#
moref(geogfn)#
#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Set the maximum number of areas any species may occupy; this cannot be larger #
# than the number of areas you set up, but it can be smaller.#
max_range_size = 4#
#
#####################################################
#####################################################
# KEY HINT: The number of states (= number of different possible geographic ranges)#
# depends on (a) the number of areas and (b) max_range_size.#
# If you have more than about 500-600 states, the calculations will get REALLY slow,#
# since the program has to exponentiate a matrix of e.g. 600x600.  Often the computer#
# will just sit there and crunch, and never get through the calculation of the first#
# likelihood.#
# #
# (this is also what is usually happening when LAGRANGE hangs: you have too many states!)#
##
# To check the number of states for a given number of ranges, try:#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=FALSE)#
numstates_from_numareas(numareas=4, maxareas=3, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=2, include_null_range=TRUE)#
#
# Large numbers of areas have problems:#
numstates_from_numareas(numareas=10, maxareas=10, include_null_range=TRUE)#
#
# ...unless you limit the max_range_size:#
numstates_from_numareas(numareas=10, maxareas=2, include_null_range=TRUE)#
#####################################################
#####################################################
#
########################################################
########################################################
# DEC AND DEC+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DEC" model is identical with #
# the Lagrange DEC model, and should return identical#
# ML estimates of parameters, and the same #
# log-likelihoods, for the same datasets.#
##
# Ancestral state probabilities at nodes will be slightly #
# different, since BioGeoBEARS is reporting the #
# ancestral state probabilities under the global ML#
# model, and Lagrange is reporting ancestral state#
# probabilities after re-optimizing the likelihood#
# after fixing the state at each node. These will #
# be similar, but not identical. See Matzke (2014),#
# Systematic Biology, for discussion.#
##
# Also see Matzke (2014) for presentation of the #
# DEC+J model.#
########################################################
########################################################
#
########################################################
########################################################
#
########################################################
# Run DEC#
########################################################
#
# Intitialize a default model (DEC model)#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
# Give BioGeoBEARS the location of the phylogeny Newick file#
BioGeoBEARS_run_object$trfn = trfn#
#
# Give BioGeoBEARS the location of the geography text file#
BioGeoBEARS_run_object$geogfn = geogfn#
#
# Input the maximum range size#
BioGeoBEARS_run_object$max_range_size = max_range_size#
#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
# 1. Here, un-comment ONLY the files you want to use.#
# 2. Also un-comment "BioGeoBEARS_run_object = section_the_tree(...", below.#
# 3. For example files see (a) extdata_dir, #
#  or (b) http://phylo.wikidot.com/biogeobears#files#
#  and BioGeoBEARS Google Group posts for further hints)#
##
# Uncomment files you wish to use in time-stratified analyses:#
BioGeoBEARS_run_object$timesfn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/timeperiods.txt", sep=""))#
BioGeoBEARS_run_object$dispersal_multipliers_fn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/dispersal_multipliers.txt", sep=""))#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
# (use more cores to speed it up; this requires#
# library(parallel) and/or library(snow). The package "parallel" #
# is now default on Macs in R 3.0+, but apparently still #
# has to be typed on some Windows machines. Note: apparently #
# parallel works on Mac command-line R, but not R.app.#
# BioGeoBEARS checks for this and resets to 1#
# core with R.app)#
#
# Sparse matrix exponentiation is an option for huge numbers of ranges/states (600+)#
# I have experimented with sparse matrix exponentiation in EXPOKIT/rexpokit,#
# but the results are imprecise and so I haven't explored it further.#
# In a Bayesian analysis, it might work OK, but the ML point estimates are#
# not identical.#
# Also, I have not implemented all functions to work with force_sparse=TRUE.#
# Volunteers are welcome to work on it!!#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC model#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
# Run this to check inputs. Read the error messages if you get them!#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = TRUE#
resfn = "Psychotria_DEC_M0_unconstrained_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDEC = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDEC = res#
    }
moref("/Library/Frameworks/R.framework/Versions/3.6/Resources/library/BioGeoBEARS/extdata/examples/Psychotria_M3strat/dispersal_multipliers.txt")
/GitHub/BioGeoBEARS/inst/extdata/examples/Psychotria_M3strat
list.files(extdata_dir)
list.files(paste0(addslash(extdata_dir), "examples"))
list.files(paste0(addslash(extdata_dir), "examples/Psychotria_M3strat"))
########################################################
# Introduction to Historical Biogeography in R#
# RStudio Cloud tutorial#
##
# 2020-11-06#
# by Nick Matzke#
##
# This tutorial is designed to be run on RStudio Cloud,#
# a free service that runs RStudio through your#
# web browser. You will need to register an RStudio Cloud#
# account (e.g. via gmail). #
##
# Go to:#
# https://rstudio.cloud/#
##
# #
# You should be able to run the following script by#
# cutting-and-pasting the below code.#
##
# Any line that starts with a "#" is a comment. These#
# lines can be pasted, or not -- it doesn't matter,#
# as commented lines are not run by R.#
##
# Please send questions to me on Zoom!#
# #
########################################################
########################################################
# This is an introductory example script for the #
# R package "BioGeoBEARS" by Nick Matzke#
# #
# All scripts are copyright Nicholas J. Matzke, #
# please cite if you use. License: GPL-3#
# http://cran.r-project.org/web/licenses/GPL-3#
# #
# I am happy to answer questions at matzke@nimbios.org, but#
# I am more happy to answer questions on the #
# BioGeoBEARS google group#
##
# The package is designed for ML and Bayesian inference#
# of #
# #
# (a) ancestral geographic ranges, and #
# #
# (b) perhaps more importantly, models for the #
#     evolution of geographic range across a phylogeny.#
##
# The example below implements and compares:#
# #
# (1) The standard 2-parameter DEC model implemented in #
#     the program LAGRANGE (Ree & Smith 2008); users will#
#     notice that the ML parameter inference and log-#
#     likelihoods are identical#
##
# (2) A DEC+J model implemented in BioGeoBEARS, wherein#
#     a third parameter, j, is added, representing the #
#     relative per-event weight of founder-event / jump#
#     speciation events at cladogenesis events.  The #
#     higher j is, the more probability these events have,#
#     and the less probability the standard LAGRANGE#
#     cladogenesis events have.#
##
# (3) Some standard model-testing (LRT and AIC) is #
#     implemented at the end so that users may compare models#
##
# (4) The script does similar tests of a DIVA-like model (Ronquist 1997)#
#     and a BAYAREA-like model (Landis, Matzke, Moore, & Huelsenbeck, 2013)#
# #
########################################################
########################################################
# SETUP -- libraries/BioGeoBEARS dependencies#
########################################################
# install.packages("GenSA")#
# install.packages("FD")#
# install.packages("snow")#
# install.packages("rexpokit")#
# install.packages("cladoRcpp")#
# install.packages("devtools")#
# Load the packages (after installation, see above).#
library(GenSA)    # GenSA is better than optimx (although somewhat slower)#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
library(rexpokit)#
library(cladoRcpp)#
########################################################
# Installing BioGeoBEARS from scratch#
# 2018-10-10 update: I have been putting the #
# updates on CRAN/GitHub#
# You should use:#
# rexpokit version 0.26.6 from CRAN#
# cladoRcpp version 0.15 from CRAN#
# BioGeoBEARS version 1.1 from GitHub, install with:#
library(devtools)#
# devtools::install_github(repo="nmatzke/BioGeoBEARS")#
########################################################
########################################################
########################################################
# #
# #
# As it is easier to maintain#
##
# # Install BioGeoBEARS from CRAN 0-cloud:#
# install.packages("BioGeoBEARS", dependencies=TRUE, repos="http://cran.rstudio.com")#
##
########################################################
library(BioGeoBEARS)#
########################################################
# SETUP: YOUR WORKING DIRECTORY#
########################################################
# You will need to set your working directory to match your local system#
#
# Note these very handy functions!#
# Command "setwd(x)" sets your working directory#
# Command "getwd()" gets your working directory and tells you what it is.#
# Command "list.files()" lists the files in your working directory#
# To get help on any command, use "?".  E.g., "?list.files"#
#
# Set your working directory for output files#
# default here is your home directory ("~")#
# Change this as you like#
wd = np("~")#
setwd(wd)#
#
# Double-check your working directory with getwd()#
getwd()#
#
########################################################
# SETUP: Extension data directory#
########################################################
# When R packages contain extra files, they are stored in the "extdata" directory #
# inside the installed package.#
##
# BioGeoBEARS contains various example files and scripts in its extdata directory.#
# #
# Each computer operating system might install BioGeoBEARS in a different place, #
# depending on your OS and settings. #
# #
# However, you can find the extdata directory like this:#
extdata_dir = np(system.file("extdata", package="BioGeoBEARS"))#
extdata_dir#
list.files(extdata_dir)#
#
# "system.file" looks in the directory of a specified package (in this case BioGeoBEARS)#
# The function "np" is just a shortcut for normalizePath(), which converts the #
# path to the format appropriate for your system (e.g., Mac/Linux use "/", but #
# Windows uses "\\", if memory serves).#
#
# Even when using your own data files, you should KEEP these commands in your #
# script, since the plot_BioGeoBEARS_results function needs a script from the #
# extdata directory to calculate the positions of "corners" on the plot. This cannot#
# be made into a straight up BioGeoBEARS function because it uses C routines #
# from the package APE which do not pass R CMD check for some reason.#
#
########################################################
# SETUP: YOUR TREE FILE AND GEOGRAPHY FILE#
########################################################
# Example files are given below. To run your own data,#
# make the below lines point to your own files, e.g.#
# trfn = "/mydata/frogs/frogBGB/tree.newick"#
# geogfn = "/mydata/frogs/frogBGB/geog.data"#
#
########################################################
# Phylogeny file#
# Notes: #
# 1. Must be binary/bifurcating: no polytomies#
# 2. No negative branchlengths (e.g. BEAST MCC consensus trees sometimes have negative branchlengths)#
# 3. Be careful of very short branches, as BioGeoBEARS will interpret ultrashort branches as direct ancestors#
# 4. You can use non-ultrametric trees, but BioGeoBEARS will interpret any tips significantly below the #
#    top of the tree as fossils!  This is only a good idea if you actually do have fossils in your tree,#
#    as in e.g. Wood, Matzke et al. (2013), Systematic Biology.#
# 5. The default settings of BioGeoBEARS make sense for trees where the branchlengths are in units of #
#    millions of years, and the tree is 1-1000 units tall. If you have a tree with a total height of#
#    e.g. 0.00001, you will need to adjust e.g. the max values of d and e, or (simpler) multiply all#
#    your branchlengths to get them into reasonable units.#
# 6. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
########################################################
# This is the example Newick file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
# "trfn" = "tree file name"#
trfn = np(paste(addslash(extdata_dir), "Psychotria_5.2.newick", sep=""))#
#
# Look at the raw Newick file:#
moref(trfn)#
#
# Look at your phylogeny (plots to a PDF, which avoids issues with multiple graphics in same window):#
pdffn = "tree.pdf"#
pdf(file=pdffn, width=9, height=12)#
#
tr = read.tree(trfn)#
tr#
plot(tr)#
title("Example Psychotria phylogeny from Ree & Smith (2008)")#
axisPhylo() # plots timescale#
#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)#
#
########################################################
# Geography file#
# Notes:#
# 1. This is a PHYLIP-formatted file. This means that in the #
#    first line, #
#    - the 1st number equals the number of rows (species)#
#    - the 2nd number equals the number of columns (number of areas)#
#    - after a tab, put the areas in parentheses, with spaces: (A B C D)#
##
# 1.5. Example first line:#
#    10    4    (A B C D)#
# #
# 2. The second line, and subsequent lines:#
#    speciesA    0110#
#    speciesB    0111#
#    speciesC    0001#
#         ...#
# #
# 2.5a. This means a TAB between the species name and the area 0/1s#
# 2.5b. This also means NO SPACE AND NO TAB between the area 0/1s.#
# #
# 3. See example files at:#
#    http://phylo.wikidot.com/biogeobears#files#
# #
# 4. Make you understand what a PLAIN-TEXT EDITOR is:#
#    http://phylo.wikidot.com/biogeobears#texteditors#
##
# 3. The PHYLIP format is the same format used for C++ LAGRANGE geography files.#
##
# 4. All names in the geography file must match names in the phylogeny file.#
##
# 5. DON'T USE SPACES IN SPECIES NAMES, USE E.G. "_"#
##
# 6. Operational taxonomic units (OTUs) should ideally be phylogenetic lineages, #
#    i.e. genetically isolated populations.  These may or may not be identical #
#    with species.  You would NOT want to just use specimens, as each specimen #
#    automatically can only live in 1 area, which will typically favor DEC+J #
#    models.  This is fine if the species/lineages really do live in single areas,#
#    but you wouldn't want to assume this without thinking about it at least. #
#    In summary, you should collapse multiple specimens into species/lineages if #
#    data indicates they are the same genetic population.#
#######################################################
#
# This is the example geography file for Hawaiian Psychotria#
# (from Ree & Smith 2008)#
geogfn = np(paste(addslash(extdata_dir), "Psychotria_geog.data", sep=""))#
#
# Look at the raw geography text file:#
moref(geogfn)#
#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Set the maximum number of areas any species may occupy; this cannot be larger #
# than the number of areas you set up, but it can be smaller.#
max_range_size = 4#
#
#####################################################
#####################################################
# KEY HINT: The number of states (= number of different possible geographic ranges)#
# depends on (a) the number of areas and (b) max_range_size.#
# If you have more than about 500-600 states, the calculations will get REALLY slow,#
# since the program has to exponentiate a matrix of e.g. 600x600.  Often the computer#
# will just sit there and crunch, and never get through the calculation of the first#
# likelihood.#
# #
# (this is also what is usually happening when LAGRANGE hangs: you have too many states!)#
##
# To check the number of states for a given number of ranges, try:#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=4, include_null_range=FALSE)#
numstates_from_numareas(numareas=4, maxareas=3, include_null_range=TRUE)#
numstates_from_numareas(numareas=4, maxareas=2, include_null_range=TRUE)#
#
# Large numbers of areas have problems:#
numstates_from_numareas(numareas=10, maxareas=10, include_null_range=TRUE)#
#
# ...unless you limit the max_range_size:#
numstates_from_numareas(numareas=10, maxareas=2, include_null_range=TRUE)#
#####################################################
#####################################################
#
########################################################
########################################################
# DEC AND DEC+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DEC" model is identical with #
# the Lagrange DEC model, and should return identical#
# ML estimates of parameters, and the same #
# log-likelihoods, for the same datasets.#
##
# Ancestral state probabilities at nodes will be slightly #
# different, since BioGeoBEARS is reporting the #
# ancestral state probabilities under the global ML#
# model, and Lagrange is reporting ancestral state#
# probabilities after re-optimizing the likelihood#
# after fixing the state at each node. These will #
# be similar, but not identical. See Matzke (2014),#
# Systematic Biology, for discussion.#
##
# Also see Matzke (2014) for presentation of the #
# DEC+J model.#
########################################################
########################################################
#
########################################################
########################################################
#
########################################################
# Run DEC#
########################################################
#
# Intitialize a default model (DEC model)#
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
#
# Give BioGeoBEARS the location of the phylogeny Newick file#
BioGeoBEARS_run_object$trfn = trfn#
#
# Give BioGeoBEARS the location of the geography text file#
BioGeoBEARS_run_object$geogfn = geogfn#
#
# Input the maximum range size#
BioGeoBEARS_run_object$max_range_size = max_range_size#
#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
# 1. Here, un-comment ONLY the files you want to use.#
# 2. Also un-comment "BioGeoBEARS_run_object = section_the_tree(...", below.#
# 3. For example files see (a) extdata_dir, #
#  or (b) http://phylo.wikidot.com/biogeobears#files#
#  and BioGeoBEARS Google Group posts for further hints)#
##
# Uncomment files you wish to use in time-stratified analyses:#
BioGeoBEARS_run_object$timesfn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/timeperiods.txt", sep=""))#
BioGeoBEARS_run_object$dispersal_multipliers_fn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/dispersal_multipliers.txt", sep=""))#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
# (use more cores to speed it up; this requires#
# library(parallel) and/or library(snow). The package "parallel" #
# is now default on Macs in R 3.0+, but apparently still #
# has to be typed on some Windows machines. Note: apparently #
# parallel works on Mac command-line R, but not R.app.#
# BioGeoBEARS checks for this and resets to 1#
# core with R.app)#
#
# Sparse matrix exponentiation is an option for huge numbers of ranges/states (600+)#
# I have experimented with sparse matrix exponentiation in EXPOKIT/rexpokit,#
# but the results are imprecise and so I haven't explored it further.#
# In a Bayesian analysis, it might work OK, but the ML point estimates are#
# not identical.#
# Also, I have not implemented all functions to work with force_sparse=TRUE.#
# Volunteers are welcome to work on it!!#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC model#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
# Run this to check inputs. Read the error messages if you get them!#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)
runslow = TRUE#
resfn = "Psychotria_DEC_M3_time-stratified_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDEC = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDEC = res#
    }#
#
########################################################
# Run DEC+J#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
BioGeoBEARS_run_object$timesfn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/timeperiods.txt", sep=""))#
BioGeoBEARS_run_object$dispersal_multipliers_fn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/dispersal_multipliers.txt", sep=""))#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DEC+J model#
# Get the ML parameter values from the 2-parameter nested model#
# (this will ensure that the 3-parameter model always does at least as good)#
dstart = resDEC$outputs@params_table["d","est"]#
estart = resDEC$outputs@params_table["e","est"]#
jstart = 0.0001#
#
# Input starting values for d, e#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = estart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = estart#
#
# Add j as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
resfn = "Psychotria_DEC+J_M3_time-stratified_v1.Rdata"#
runslow = TRUE#
if (runslow)#
    {#
    #sourceall("/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
#
    resDECj = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDECj = res#
    }#
#
########################################################
# PDF plots#
########################################################
pdffn = "Psychotria_DEC_vs_DEC+J_M3_time-stratified_v1.pdf"#
pdf(pdffn, width=6, height=6)#
#
########################################################
# Plot ancestral states - DEC#
########################################################
analysis_titletxt ="BioGeoBEARS DEC on Psychotria M3_time-stratified"#
#
# Setup#
results_object = resDEC#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res2 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
########################################################
# Plot ancestral states - DECJ#
########################################################
analysis_titletxt ="BioGeoBEARS DEC+J on Psychotria M3_time-stratified"#
#
# Setup#
results_object = resDECj#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
dev.off()  # Turn off PDF#
cmdstr = paste("open ", pdffn, sep="")#
system(cmdstr) # Plot it#
#
########################################################
########################################################
# DIVALIKE AND DIVALIKE+J ANALYSIS#
########################################################
########################################################
# NOTE: The BioGeoBEARS "DIVALIKE" model is not identical with #
# Ronquist (1997)'s parsimony DIVA. It is a likelihood#
# interpretation of DIVA, constructed by modelling DIVA's#
# processes the way DEC does, but only allowing the #
# processes DIVA allows (widespread vicariance: yes; subset#
# sympatry: no; see Ronquist & Sanmartin 2011, Figure 4).#
##
# DIVALIKE is a likelihood interpretation of parsimony#
# DIVA, and it is "like DIVA" -- similar to, but not#
# identical to, parsimony DIVA.#
##
# I thus now call the model "DIVALIKE", and you should also. ;-)#
########################################################
########################################################
#
########################################################
# Run DIVALIKE#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
BioGeoBEARS_run_object$timesfn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/timeperiods.txt", sep=""))#
BioGeoBEARS_run_object$dispersal_multipliers_fn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/dispersal_multipliers.txt", sep=""))#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DIVALIKE model#
# Remove subset-sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "2-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/2"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "ysv*1/2"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "ysv*1/2"#
#
# Allow classic, widespread vicariance; all events equiprobable#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01v","init"] = 0.5#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01v","est"] = 0.5#
#
# No jump dispersal/founder-event speciation#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = 0.01#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = 0.01#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
runslow = TRUE#
resfn = "Psychotria_DIVALIKE_M3_time-stratified_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resDIVALIKE = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDIVALIKE = res#
    }#
#
########################################################
# Run DIVALIKE+J#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
BioGeoBEARS_run_object$timesfn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/timeperiods.txt", sep=""))#
BioGeoBEARS_run_object$dispersal_multipliers_fn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/dispersal_multipliers.txt", sep=""))#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up DIVALIKE+J model#
# Get the ML parameter values from the 2-parameter nested model#
# (this will ensure that the 3-parameter model always does at least as good)#
dstart = resDIVALIKE$outputs@params_table["d","est"]#
estart = resDIVALIKE$outputs@params_table["e","est"]#
jstart = 0.0001#
#
# Input starting values for d, e#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = estart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = estart#
#
# Remove subset-sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "2-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/2"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "ysv*1/2"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "ysv*1/2"#
#
# Allow classic, widespread vicariance; all events equiprobable#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01v","init"] = 0.5#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01v","est"] = 0.5#
#
# Add jump dispersal/founder-event speciation#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
# Under DIVALIKE+J, the max of "j" should be 2, not 3 (as is default in DEC+J)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","max"] = 1.99999#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
resfn = "Psychotria_DIVALIKE+J_M3_time-stratified_v1.Rdata"#
runslow = TRUE#
if (runslow)#
    {#
    #sourceall("/Dropbox/_njm/__packages/BioGeoBEARS_setup/")#
#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
#
    resDIVALIKEj = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resDIVALIKEj = res#
    }#
#
pdffn = "Psychotria_DIVALIKE_vs_DIVALIKE+J_M3_time-stratified_v1.pdf"#
pdf(pdffn, width=6, height=6)#
#
########################################################
# Plot ancestral states - DIVALIKE#
########################################################
analysis_titletxt ="BioGeoBEARS DIVALIKE on Psychotria M3_time-stratified"#
#
# Setup#
results_object = resDIVALIKE#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res2 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
########################################################
# Plot ancestral states - DIVALIKE+J#
########################################################
analysis_titletxt ="BioGeoBEARS DIVALIKE+J on Psychotria M3_time-stratified"#
#
# Setup#
results_object = resDIVALIKEj#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
dev.off()#
cmdstr = paste("open ", pdffn, sep="")#
system(cmdstr)#
#
########################################################
########################################################
# BAYAREALIKE AND BAYAREALIKE+J ANALYSIS#
########################################################
########################################################
# NOTE: As with DIVA, the BioGeoBEARS BayArea-like model is #
# not identical with the full Bayesian model implemented #
# in the "BayArea" program of Landis et al. (2013). #
##
# Instead, this is a simplified likelihood interpretation#
# of the model.  Basically, in BayArea and BioGeoBEARS-BAYAREALIKE, #
# "d" and "e" work like they do in the DEC model of Lagrange #
# (and BioGeoBEARS), and then BayArea's cladogenesis assumption#
# (which is that nothing in particular happens at cladogenesis) is #
# replicated by BioGeoBEARS.#
##
# This leaves out 3 important things that are in BayArea:#
# 1. Distance dependence (you can add this with a distances #
#    matrix + the "x" parameter in BioGeoBEARS, however)#
# 2. A correction for disallowing "e" events that drive#
#    a species extinct (a null geographic range)#
# 3. The neat Bayesian sampling of histories, which allows#
#    analyses on large numbers of areas.#
##
# The main purpose of having a "BAYAREALIKE" model is #
# to test the importance of the cladogenesis model on #
# particular datasets. Does it help or hurt the data #
# likelihood if there is no special cladogenesis process?#
# #
# BAYAREALIKE is a likelihood interpretation of BayArea,#
# and it is "like BayArea" -- similar to, but not#
# identical to, Bayesian BayArea.#
# I thus now call the model "BAYAREALIKE", and you should also. ;-)#
########################################################
########################################################
#
########################################################
# Run BAYAREALIKE#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
BioGeoBEARS_run_object$timesfn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/timeperiods.txt", sep=""))#
BioGeoBEARS_run_object$dispersal_multipliers_fn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/dispersal_multipliers.txt", sep=""))#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"    # if FALSE, use optim() instead of optimx()#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up BAYAREALIKE model#
# No subset sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
# No vicariance#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","est"] = 0.0#
#
# No jump dispersal/founder-event speciation#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = 0.01#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = 0.01#
#
# Adjust linkage between parameters#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "1-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "1-j"#
#
# Only sympatric/range-copying (y) events allowed, and with #
# exact copying (both descendants always the same size as the ancestor)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","init"] = 0.9999#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","est"] = 0.9999#
#
# Check the inputs#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
runslow = TRUE#
resfn = "Psychotria_BAYAREALIKE_M3_time-stratified_v1.Rdata"#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
    resBAYAREALIKE = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resBAYAREALIKE = res#
    }#
#
########################################################
# Run BAYAREALIKE+J#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$trfn = trfn#
BioGeoBEARS_run_object$geogfn = geogfn#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$min_branchlength = 0.000001    # Min to treat tip as a direct ancestor (no speciation event)#
BioGeoBEARS_run_object$include_null_range = TRUE    # set to FALSE for e.g. DEC* model, DEC*+J, etc.#
# (For DEC* and other "*" models, please cite: Massana, Kathryn A.; Beaulieu, #
#  Jeremy M.; Matzke, Nicholas J.; O’Meara, Brian C. (2015). Non-null Effects of #
#  the Null Range in Biogeographic Models: Exploring Parameter Estimation in the #
#  DEC Model. bioRxiv,  http://biorxiv.org/content/early/2015/09/16/026914 )#
# Also: search script on "include_null_range" for other places to change#
#
# Set up a time-stratified analysis:#
BioGeoBEARS_run_object$timesfn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/timeperiods.txt", sep=""))#
BioGeoBEARS_run_object$dispersal_multipliers_fn = np(paste(addslash(extdata_dir), "examples/Psychotria_M3strat/BGB/dispersal_multipliers.txt", sep=""))#
#BioGeoBEARS_run_object$areas_allowed_fn = "areas_allowed.txt"#
#BioGeoBEARS_run_object$areas_adjacency_fn = "areas_adjacency.txt"#
#BioGeoBEARS_run_object$distsfn = "distances_matrix.txt"#
# See notes on the distances model on PhyloWiki's BioGeoBEARS updates page.#
#
# Speed options and multicore processing if desired#
BioGeoBEARS_run_object$on_NaN_error = -1e50    # returns very low lnL if parameters produce NaN error (underflow check)#
BioGeoBEARS_run_object$speedup = TRUE          # shorcuts to speed ML search; use FALSE if worried (e.g. >3 params)#
BioGeoBEARS_run_object$use_optimx = "GenSA"#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$force_sparse = FALSE    # force_sparse=TRUE causes pathology & isn't much faster at this scale#
#
# This function loads the dispersal multiplier matrix etc. from the text files into the model object. Required for these to work!#
# (It also runs some checks on these inputs for certain errors.)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# Divide the tree up by timeperiods/strata (uncomment this for stratified analysis)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
# The stratified tree is described in this table:#
#BioGeoBEARS_run_object$master_table#
#
# Good default settings to get ancestral states#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE    # get ancestral states from optim run#
#
# Set up BAYAREALIKE+J model#
# Get the ML parameter values from the 2-parameter nested model#
# (this will ensure that the 3-parameter model always does at least as good)#
dstart = resBAYAREALIKE$outputs@params_table["d","est"]#
estart = resBAYAREALIKE$outputs@params_table["e","est"]#
jstart = 0.0001#
#
# Input starting values for d, e#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = dstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = estart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = estart#
#
# No subset sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
# No vicariance#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","est"] = 0.0#
#
# *DO* allow jump dispersal/founder-event speciation (set the starting value close to 0)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
# Under BAYAREALIKE+J, the max of "j" should be 1, not 3 (as is default in DEC+J) or 2 (as in DIVALIKE+J)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","max"] = 0.99999#
#
# Adjust linkage between parameters#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "1-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "1-j"#
#
# Only sympatric/range-copying (y) events allowed, and with #
# exact copying (both descendants always the same size as the ancestor)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","init"] = 0.9999#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","est"] = 0.9999#
#
# NOTE (NJM, 2014-04): BAYAREALIKE+J seems to crash on some computers, usually Windows #
# machines. I can't replicate this on my Mac machines, but it is almost certainly#
# just some precision under-run issue, when optim/optimx tries some parameter value #
# just below zero.  The "min" and "max" options on each parameter are supposed to#
# prevent this, but apparently optim/optimx sometimes go slightly beyond #
# these limits.  Anyway, if you get a crash, try raising "min" and lowering "max" #
# slightly for each parameter:#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","min"] = 0.0000001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","max"] = 4.9999999#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","min"] = 0.0000001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","max"] = 4.9999999#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","max"] = 0.99999#
#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
resfn = "Psychotria_BAYAREALIKE+J_M3_time-stratified_v1.Rdata"#
runslow = TRUE#
if (runslow)#
    {#
    res = bears_optim_run(BioGeoBEARS_run_object)#
    res    #
#
    save(res, file=resfn)#
#
    resBAYAREALIKEj = res#
    } else {#
    # Loads to "res"#
    load(resfn)#
    resBAYAREALIKEj = res#
    }#
#
pdffn = "Psychotria_BAYAREALIKE_vs_BAYAREALIKE+J_M3_time-stratified_v1.pdf"#
pdf(pdffn, width=6, height=6)#
#
########################################################
# Plot ancestral states - BAYAREALIKE#
########################################################
analysis_titletxt ="BioGeoBEARS BAYAREALIKE on Psychotria M3_time-stratified"#
#
# Setup#
results_object = resBAYAREALIKE#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res2 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
########################################################
# Plot ancestral states - BAYAREALIKE+J#
########################################################
analysis_titletxt ="BioGeoBEARS BAYAREALIKE+J on Psychotria M3_time-stratified"#
#
# Setup#
results_object = resBAYAREALIKEj#
scriptdir = np(system.file("extdata/a_scripts", package="BioGeoBEARS"))#
#
# States#
res1 = plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="text", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
# Pie chart#
plot_BioGeoBEARS_results(results_object, analysis_titletxt, addl_params=list("j"), plotwhat="pie", label.offset=0.45, tipcex=0.7, statecex=0.7, splitcex=0.6, titlecex=0.8, plotsplits=TRUE, cornercoords_loc=scriptdir, include_null_range=TRUE, tr=tr, tipranges=tipranges)#
#
dev.off()#
cmdstr = paste("open ", pdffn, sep="")#
system(cmdstr)#
#
##########################################################################
##########################################################################
##########################################################################
##########################################################################
# #
# CALCULATE SUMMARY STATISTICS TO COMPARE#
# DEC, DEC+J, DIVALIKE, DIVALIKE+J, BAYAREALIKE, BAYAREALIKE+J#
# #
##########################################################################
##########################################################################
##########################################################################
##########################################################################
#
##########################################################################
##########################################################################
# REQUIRED READING:#
##
# Practical advice / notes / basic principles on statistical model #
#    comparison in general, and in BioGeoBEARS:#
# http://phylo.wikidot.com/advice-on-statistical-model-comparison-in-biogeobears#
##########################################################################
##########################################################################
#
# Set up empty tables to hold the statistical results#
restable = NULL#
teststable = NULL#
#
########################################################
# Statistics -- DEC vs. DEC+J#
########################################################
# We have to extract the log-likelihood differently, depending on the #
# version of optim/optimx#
LnL_2 = get_LnL_from_BioGeoBEARS_results_object(resDEC)#
LnL_1 = get_LnL_from_BioGeoBEARS_results_object(resDECj)#
#
numparams1 = 3#
numparams2 = 2#
stats = AICstats_2models(LnL_1, LnL_2, numparams1, numparams2)#
stats#
#
# DEC, null model for Likelihood Ratio Test (LRT)#
res2 = extract_params_from_BioGeoBEARS_results_object(results_object=resDEC, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
# DEC+J, alternative model for Likelihood Ratio Test (LRT)#
res1 = extract_params_from_BioGeoBEARS_results_object(results_object=resDECj, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
#
# The null hypothesis for a Likelihood Ratio Test (LRT) is that two models#
# confer the same likelihood on the data. See: Brian O'Meara's webpage:#
# http://www.brianomeara.info/tutorials/aic#
# ...for an intro to LRT, AIC, and AICc#
#
rbind(res2, res1)#
tmp_tests = conditional_format_table(stats)#
#
restable = rbind(restable, res2, res1)#
teststable = rbind(teststable, tmp_tests)#
#
########################################################
# Statistics -- DIVALIKE vs. DIVALIKE+J#
########################################################
# We have to extract the log-likelihood differently, depending on the #
# version of optim/optimx#
LnL_2 = get_LnL_from_BioGeoBEARS_results_object(resDIVALIKE)#
LnL_1 = get_LnL_from_BioGeoBEARS_results_object(resDIVALIKEj)#
#
numparams1 = 3#
numparams2 = 2#
stats = AICstats_2models(LnL_1, LnL_2, numparams1, numparams2)#
stats#
#
# DIVALIKE, null model for Likelihood Ratio Test (LRT)#
res2 = extract_params_from_BioGeoBEARS_results_object(results_object=resDIVALIKE, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
# DIVALIKE+J, alternative model for Likelihood Ratio Test (LRT)#
res1 = extract_params_from_BioGeoBEARS_results_object(results_object=resDIVALIKEj, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
#
rbind(res2, res1)#
conditional_format_table(stats)#
#
tmp_tests = conditional_format_table(stats)#
#
restable = rbind(restable, res2, res1)#
teststable = rbind(teststable, tmp_tests)#
#
########################################################
# Statistics -- BAYAREALIKE vs. BAYAREALIKE+J#
########################################################
# We have to extract the log-likelihood differently, depending on the #
# version of optim/optimx#
LnL_2 = get_LnL_from_BioGeoBEARS_results_object(resBAYAREALIKE)#
LnL_1 = get_LnL_from_BioGeoBEARS_results_object(resBAYAREALIKEj)#
#
numparams1 = 3#
numparams2 = 2#
stats = AICstats_2models(LnL_1, LnL_2, numparams1, numparams2)#
stats#
#
# BAYAREALIKE, null model for Likelihood Ratio Test (LRT)#
res2 = extract_params_from_BioGeoBEARS_results_object(results_object=resBAYAREALIKE, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
# BAYAREALIKE+J, alternative model for Likelihood Ratio Test (LRT)#
res1 = extract_params_from_BioGeoBEARS_results_object(results_object=resBAYAREALIKEj, returnwhat="table", addl_params=c("j"), paramsstr_digits=4)#
#
rbind(res2, res1)#
conditional_format_table(stats)#
#
tmp_tests = conditional_format_table(stats)#
#
restable = rbind(restable, res2, res1)#
teststable = rbind(teststable, tmp_tests)#
#
##########################################################################
# ASSEMBLE RESULTS TABLES: DEC, DEC+J, DIVALIKE, DIVALIKE+J, BAYAREALIKE, BAYAREALIKE+J#
##########################################################################
teststable$alt = c("DEC+J", "DIVALIKE+J", "BAYAREALIKE+J")#
teststable$null = c("DEC", "DIVALIKE", "BAYAREALIKE")#
row.names(restable) = c("DEC", "DEC+J", "DIVALIKE", "DIVALIKE+J", "BAYAREALIKE", "BAYAREALIKE+J")#
restable = put_jcol_after_ecol(restable)#
restable#
#
# Look at the results!!#
restable#
teststable#
#
########################################################
# Save the results tables for later -- check for e.g.#
# convergence issues#
########################################################
#
# Loads to "restable"#
# save(restable, file="restable_v1.Rdata")#
# load(file="restable_v1.Rdata")#
#
# Loads to "teststable"#
# save(teststable, file="teststable_v1.Rdata")#
# load(file="teststable_v1.Rdata")#
#
# Also save to text files#
# write.table(restable, file="restable.txt", quote=FALSE, sep="\t")#
# write.table(unlist_df(teststable), file="teststable.txt", quote=FALSE, sep="\t")#
#
########################################################
# Model weights of all six models#
########################################################
restable2 = restable#
#
# With AICs:#
AICtable = calc_AIC_column(LnL_vals=restable$LnL, nparam_vals=restable$numparams)#
restable = cbind(restable, AICtable)#
restable_AIC_rellike = AkaikeWeights_on_summary_table(restable=restable, colname_to_use="AIC")#
restable_AIC_rellike = put_jcol_after_ecol(restable_AIC_rellike)#
conditional_format_table(restable_AIC_rellike)#
#
# With AICcs -- factors in sample size#
samplesize = length(tr$tip.label)#
AICtable = calc_AICc_column(LnL_vals=restable$LnL, nparam_vals=restable$numparams, samplesize=samplesize)#
restable2 = cbind(restable2, AICtable)#
restable_AICc_rellike = AkaikeWeights_on_summary_table(restable=restable2, colname_to_use="AICc")#
restable_AICc_rellike = put_jcol_after_ecol(restable_AICc_rellike)#
conditional_format_table(restable_AICc_rellike)#
# Also save to text files#
# write.table(restable_AIC_rellike, file="restable_AIC_rellike.txt", quote=FALSE, sep="\t")#
# write.table(restable_AICc_rellike, file="restable_AICc_rellike.txt", quote=FALSE, sep="\t")#
# #
# Save with nice conditional formatting#
# write.table(conditional_format_table(restable_AIC_rellike), file="restable_AIC_rellike_formatted.txt", quote=FALSE, sep="\t")#
# write.table(conditional_format_table(restable_AICc_rellike), file="restable_AICc_rellike_formatted.txt", quote=FALSE, sep="\t")
devtools::install_github(repo="nmatzke/BioGeoBEARS")
BioGeoBEARS_run_object
names(BioGeoBEARS_run_object)
simulate_biogeog_history
n = (1877963 + 2089104)#
p = 0.459#
q = (1-p)#
sd = sqrt(n*p*q)#
#
95% CI is basically#
#
n*p - 1.96*sd#
n*p + 1.96*sd
# Calculation of SD for binomial distribution #
# based on 2016 results#
n = (1877963 + 2089104)#
p = 0.459#
q = (1-p)#
#
sd = sqrt(n*p*q)#
sd#
# #
#
# 95% CI is basically#
#
n*p - 1.96*sd#
n*p + 1.96*sd
1.96*sd
1877963/n
1945.341/n
fn = "~/Desktop/__screencap/__220/_2020t2_grades/2020t2_grades_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)
df
library(psych)
install.packages("psych")
scatterHist()
library(psych)
scatterHist(library(psych)#
fn = "~/Desktop/__screencap/__220/_2020t2_grades/2020t2_grades_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
scatterHist(x=df)
scatterHist(x=df$coursework, y=df$final)
library(psych)#
fn = "~/Desktop/__screencap/__220/_2020t2_grades/2020t2_grades_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
scatterHist(x=df$coursework, y=df$final)
? scatterHist
scatterHist(x=final~coursework, y=df$final, smooth=FALSE, ab=TRUE, correl=TRUE, data=df)
library(psych)#
fn = "~/Desktop/__screencap/__220/_2020t2_grades/2020t2_grades_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
scatterHist(x=final~coursework, y=df$final, smooth=FALSE, ab=TRUE, correl=TRUE, data=df, ellipse=FALE, x.breaks=50, y.breaks=50)
library(psych)#
fn = "~/Desktop/__screencap/__220/_2020t2_grades/2020t2_grades_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
scatterHist(x=final~coursework, y=df$final, smooth=FALSE, ab=TRUE, correl=TRUE, data=df, ellipse=FALSE, x.breaks=50, y.breaks=50)
library(psych)#
fn = "~/Desktop/__screencap/__220/_2020t2_grades/2020t2_grades_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
scatterHist(x=final~coursework, y=df$final, smooth=FALSE, ab=TRUE, correl=TRUE, data=df, ellipse=FALSE, x.breaks=50, y.breaks=50, y.axes=TRUE)
?mtext
mtext(text="final exam score", side=2, line=2)
mtext(text="final exam score", side=2, line=0)
mtext(text="final exam score", side=2, line=20)
mtext(text="final exam score", side=2, line=24)
mtext(text="final exam score", side=2, line=26)
library(psych)#
fn = "~/Desktop/__screencap/__220/_2020t2_grades/2020t2_grades_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
scatterHist(x=final~coursework, y=df$final, smooth=FALSE, ab=TRUE, correl=TRUE, data=df, ellipse=FALSE, x.breaks=50, y.breaks=50, y.axes=TRUE)#
mtext(text="final exam score", side=2, line=26)
~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt
\
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
table(df)
rev(sort(tdf))
tdf = table(df)#
rev(sort(tdf))
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
# Remove "-BSC" (Bachelors of Science)#
df = grepl(pattern="-BSC", replacement="", x=df)#
#
tdf = table(df)#
rev(sort(tdf))
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
# Remove "-BSC" (Bachelors of Science)#
df = gsub(pattern="-BSC", replacement="", x=df)#
#
tdf = table(df)#
rev(sort(tdf))
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
# Remove "-BSC" (Bachelors of Science)#
df[] = gsub(pattern="-BSC", replacement="", x=df[])#
#
tdf = table(df)#
rev(sort(tdf))
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)
gsub(pattern="-BSC", replacement="", x=df[])
df
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
sort(unique(df))
sort(unique(df[,1]))
cat(sort(unique(df[,1])), sep="\n")
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
names(rev(sort(tdf)))
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
########################################################
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BNBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBN", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BNBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBN", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBM", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BNBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBN", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSMOD", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))
fn = "~/Desktop/__screencap/__220/codes_for_majors.txt"#
codes = read.table(fn, sep="\t", header=TRUE)
codes
# Codes for majors#
fn = "~/Desktop/__screencap/__220/codes_for_majors.txt"#
codes = read.table(fn, sep="\t", header=TRUE)#
#
########################################################
# 2020, semester 1+2 majors#
########################################################
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BNBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBN", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCOM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSMOD", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-LBBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-COPUA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-GDSCI", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))#
########################################################
# Change the codes#
########################################################
for (i in 1:nrow(codes))#
	{#
	code = codes[i,1]#
	major = codes[i,2]#
	TF = df[,1] == code#
	df[TF,1] = major#
	}#
#
tdf = table(df)#
rev(sort(tdf))
pie(tdf)
pie(sort(tdf))
?pie
# Codes for majors#
fn = "~/Desktop/__screencap/__220/codes_for_majors.txt"#
codes = read.table(fn, sep="\t", header=TRUE)#
#
########################################################
# 2020, semester 1+2 majors#
########################################################
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BNBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBN", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCOM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSMOD", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-LBBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-COPUA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-GDSCI", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))#
########################################################
# Change the codes#
########################################################
for (i in 1:nrow(codes))#
	{#
	code = codes[i,1]#
	major = codes[i,2]#
	TF = df[,1] == code#
	df[TF,1] = major#
	}#
#
tdf = table(df)#
rev(sort(tdf))#
uniq_names = unique(df[,1])#
for (i in 1:length(uniq_names))#
	{#
	TF = df[,1] == uniq_names[i]#
	if (sum(TF) <= 1)#
		{#
		df[TF,1] = "other (singletons)"#
		}#
	}#
#
tdf = table(df)#
pie(rev(sort(tdf)))
rainbow(10)
length(tdf)
fn = "~/Desktop/__screencap/__220/codes_for_majors.txt"#
codes = read.table(fn, sep="\t", header=TRUE)#
#
########################################################
# 2020, semester 1+2 majors#
########################################################
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BNBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBN", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCOM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSMOD", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-LBBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-COPUA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-GDSCI", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))#
########################################################
# Change the codes#
########################################################
for (i in 1:nrow(codes))#
	{#
	code = codes[i,1]#
	major = codes[i,2]#
	TF = df[,1] == code#
	df[TF,1] = major#
	}#
#
tdf = table(df)#
rev(sort(tdf))#
uniq_names = unique(df[,1])#
for (i in 1:length(uniq_names))#
	{#
	TF = df[,1] == uniq_names[i]#
	if (sum(TF) <= 1)#
		{#
		df[TF,1] = "other (singletons)"#
		}#
	}#
#
tdf = table(df)#
#
colors = c(rainbow(10), rep("white", length(tdf)-10))#
pie(rev(sort(tdf)), col=colors)
colors = c(rainbow(15), rep("white", length(tdf)-15))#
pie(rev(sort(tdf)), col=colors)
dim(df)
pie(rev(sort(tdf)), col=colors)#
title("Majors of BIOSCI220 students\n(2021, semester 1+2 enrolment, n=481")
# Codes for majors#
fn = "~/Desktop/__screencap/__220/codes_for_majors.txt"#
codes = read.table(fn, sep="\t", header=TRUE)#
#
########################################################
# 2020, semester 1+2 majors#
########################################################
fn = "~/Desktop/__screencap/__220/2021s1-2_majors_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
#
cat(sort(unique(df[,1])), sep="\n")#
#
# Remove "-BSC" (Bachelors of Science)#
df[,1] = gsub(pattern="-BSC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BABS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSLB", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BGBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBG", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BNBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBN", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSBC", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BCOM", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-BSMOD", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-LBBS", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-COPUA", replacement="", x=df[,1])#
df[,1] = gsub(pattern="-GDSCI", replacement="", x=df[,1])#
#
tdf = table(df)#
rev(sort(tdf))#
########################################################
# Change the codes#
########################################################
for (i in 1:nrow(codes))#
	{#
	code = codes[i,1]#
	major = codes[i,2]#
	TF = df[,1] == code#
	df[TF,1] = major#
	}#
#
tdf = table(df)#
rev(sort(tdf))#
uniq_names = unique(df[,1])#
for (i in 1:length(uniq_names))#
	{#
	TF = df[,1] == uniq_names[i]#
	if (sum(TF) <= 1)#
		{#
		df[TF,1] = "other (singletons)"#
		}#
	}#
#
tdf = table(df)#
#
colors = c(rainbow(15), rep("white", length(tdf)-15))#
colors[5] = "grey50" # other (singletons)#
pie(rev(sort(tdf)), col=colors)#
title("Majors of BIOSCI220 students\n(2021, semester 1+2 enrolment, n=481")
colors[5] = "grey20" # other (singletons)#
pie(rev(sort(tdf)), col=colors)#
title("Majors of BIOSCI220 students\n(2021, semester 1+2 enrolment, n=481")
colors[5] = "grey90" # other (singletons)#
pie(rev(sort(tdf)), col=colors)#
title("Majors of BIOSCI220 students\n(2021, semester 1+2 enrolment, n=481")
colors = c(rainbow(18), rep("white", length(tdf)-18))#
colors[5] = "grey90" # other (singletons)#
pie(rev(sort(tdf)), col=colors)#
title("Majors of BIOSCI220 students\n(2021, semester 1+2 enrolment, n=481")
colors = c(rainbow(15), rep("white", length(tdf)-15))#
colors[5] = "grey90" # other (singletons)#
pie(rev(sort(tdf)), col=colors)#
title("Majors of BIOSCI220 students\n(2021, semester 1+2 enrolment, n=481")
colors = c(rainbow(15), rep("white", length(tdf)-15))#
colors[5] = "grey90" # other (singletons)#
pie(rev(sort(tdf)), col=colors)#
title("Majors of BIOSCI220 students\n(2021, semester 1+2 enrolment, n=481)")
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
#
tdf = table(df$Residency)#
rev(sort(tdf))
tdf = table(df$Ethnicity)#
rev(sort(tdf))
df$Birthdate = as.Date(df$Birthdate)#
df$Birthdate
?as.Date
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%Y")#
df$Birthdate
as.Year(df$Birthdate)
df$Birthdate
class(df$Birthdate)
df$Birthdate$year
install.packages("lubridate")
install.packages("tidyverse")
library(devtools)
devtools::install_github("tidyverse/lubridate")
library(lubridate)
date(df$Birthdate)
year(df$Birthdate)
df$Birthdate+1900
df$Birthdate+1
df$Birthdate
as.Date(1900)
as.Date("1900-01-01")
year(df$Birthdate)
library(lubridate)#
#
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%Y")#
df$Birthdate#
#
# Add year#
TF = year(df$Birthdate) > 25#
df$Birthdate[TF] = df$Birthdate[TF] + as.Date("1900-01-01")#
TF = year(df$Birthdate) <= 25#
df$Birthdate[TF] = df$Birthdate[TF] + as.Date("2000-01-01")#
df$Birthdate
df$Birthdate[TF]
class(df$Birthdate[TF])
class(as.Date("1900-01-01"))
df$Birthdate[TF][1] + as.Date("1900-01-01")
df$Birthdate[TF][1]
x=df$Birthdate[TF][1]
y=as.Date("1900-01-01")
x
x+y
as.POSIXlt(x)
as.POSIXlt(df$Birthdate[TF]) + as.POSIXlt(as.Date("1900-01-01"))
as.POSIXlt(df$Birthdate[TF]) + as.Date("1900-01-01")
as.POSIXlt(x) + as.POSIXlt(y)
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%y")#
df$Birthdate
'#
library(lubridate)#
#
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%y")#
df$Birthdate#
#
# Add year#
tmp = df$Birthdate#
for (i in 1:length(tmp))#
	{#
  newdate = as.POSIXlt(tmp[i])#
  if (newdate$year > 25)#
		{#
		newdate$year = newdate$year + 1900#
		} else {#
		newdate$year = newdate$year + 2000#
		}#
	tmp[i] = as.Date(newdate)#
  }#
df$Birthdate = tmp#
df$Birthdate
}
}}
tmp = df$Birthdate#
for (i in 1:length(tmp))#
	{#
  newdate = as.POSIXlt(tmp[i])#
  if (newdate$year > 25)#
		{#
		newdate$year = newdate$year + 1900#
		} else {#
		newdate$year = newdate$year + 2000#
		}#
	tmp[i] = as.Date(newdate)#
  }
tmp
library(lubridate)#
#
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%y")#
df$Birthdate#
#
# Add year#
tmp = df$Birthdate#
for (i in 1:length(tmp))#
	{#
  newdate = as.POSIXlt(tmp[i])#
  if (newdate$year > 25)#
		{#
		newdate$year = newdate$year + 1900#
		} else {#
		newdate$year = newdate$year + 2000#
		}#
	tmp[i] = as.Date(newdate)#
  }
df$Birthdate = tmp#
df$Birthdate
library(lubridate)#
#
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%y")#
df$Birthdate#
#
# Add year#
tmp = df$Birthdate#
for (i in 1:length(tmp))#
	{#
  newdate = as.POSIXlt(tmp[i])#
  if (newdate$year > 25)#
		{#
		newdate$year = newdate$year + 1900#
		} else {#
		newdate$year = newdate$year + 2000#
		}#
	tmp[i] = as.Date(newdate)#
  }#
df$Birthdate = tmp#
df$Birthdate
library(lubridate)#
#
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%y")#
df$Birthdate
library(lubridate)#
#
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%Y")#
df$Birthdate
tdf = table(df$Residency)#
rev(sort(tdf))#
#
tdf = table(df$Ethnicity)#
rev(sort(tdf))
hist(df$Birthdate, breaks=50)
df$Birthdate
fn = "~/Desktop/__screencap/__220/2021s1-2_demographics_v1.txt"#
df = read.table(fn, sep="\t", header=TRUE)#
head(df)#
df$Birthdate = as.Date(df$Birthdate, format="%m-%d-%y")#
df$Birthdate#
#
hist(df$Birthdate, breaks=50)
pdffn = "BIOSCI220_piecharts.pdf"#
pdf(file=pdffn, width=6, height=6)#
#
hist(df$Birthdate, breaks=50)#
tdf = table(df$Residency)#
rev(sort(tdf))#
pie(rev(sort(tdf)))#
#
tdf = table(df$Ethnicity)#
rev(sort(tdf))#
pie(rev(sort(tdf)))#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)
pdffn = "~/Desktop/__screencap/__220/BIOSCI220_piecharts.pdf"#
pdf(file=pdffn, width=6, height=6)#
#
hist(df$Birthdate, breaks=50)#
tdf = table(df$Residency)#
rev(sort(tdf))#
pie(rev(sort(tdf)))#
#
tdf = table(df$Ethnicity)#
rev(sort(tdf))#
pie(rev(sort(tdf)))#
dev.off()#
cmdstr = paste0("open ", pdffn)#
system(cmdstr)
library(BioGeoBEARS)
bears_optim_run
library(BioGeoBEARS)
numstates_from_numareas(numareas=19, maxareas=19, include_null_range=TRUE)
library(rexpokit)
numstates_from_numareas(numareas=19, maxareas=19, include_null_range=TRUE)
library(cladoRcpp)
numstates_from_numareas(numareas=19, maxareas=19, include_null_range=TRUE)
524288^2
numstates_from_numareas(numareas=19, maxareas=2 include_null_range=TRUE)
numstates_from_numareas(numareas=19, maxareas=2, include_null_range=TRUE)
library(DDD)
library(RPANDA)
install.packages("RPANDA")
library(RPANDA)
?likelihood_subgroup_model
library(cladoRcpp)#
library(BioGeoBERS)#
numstates_from_numareas(numareas=19, maxareas=19, include_null_range=TRUE)
library(cladoRcpp)#
library(BioGeoBEARS)#
numstates_from_numareas(numareas=19, maxareas=19, include_null_range=TRUE)
library(cladoRcpp)#
library(BioGeoBEARS)#
numstates_from_numareas(numareas=19, maxareas=3, include_null_range=TRUE)
20000/30
20000/30/40
library(BioGeoBEARS)
plot_BioGeoBEARS_results
fn = "https://covid.ourworldindata.org/data/owid-covid-data.csv"#
data = read.csv(file=fn)#
dim(data)
dim(data)#
nrow(data)#
ncol(data)#
head(data)#
tail(data)#
names(data)#
class(data)#
########################################################
# Accessing particular columns of data#
########################################################
# With R data.frames, you can access individual columns#
# using "$columnname"#
#
# For example, here is the country name for each row of data:#
#
data$location#
#
# That's a lot of countries!  We can use the function "unique" to #
# get just one entry for each country#
#
unique(data$location)#
########################################################
# Plotting the data#
# Below, I have a script to plot the number of new#
# cases, per day, for New Zealand#
########################################################
#
# Specify the country name#
country_name = "New Zealand"#
#
# The "==" symbol gives TRUE or FALSE#
# Here, we are seeing, for each row, if it matches #
# "New Zealand".#
##
TF = data$location == country_name#
#
# R treats FALSE as 0, and TRUE as 1, so doing sum(TF)#
# gives us the number of TRUE values#
sum(TF)#
#
# We can subset the table "data" to a smaller table, "d",#
# by using square brackets. Square brackets indicate which #
# [rows,columns] of the data table you want, where blank =#
# "give everything".#
##
# So, this command subsets the table "data" to all rows#
# where location == "New Zealand"#
d = data[TF,]#
#
# How big is the new table?#
dim(d)#
#
# Let's plot date versus cases, for New Zealand#
plot(x=d$date, y=d$new_cases)#
#
# Why didn't that work?  Look at d$date:#
d$date#
class(d$date)#
#
# If the "class" of the data is "character", and if R can't easily #
# convert it to numbers (class "numeric"), then R gives an error.#
#
# We can fix this by forcing R to read the dates as datatype date,#
# using the "as.Date" function:#
#
plot(x=as.Date(d$date), y=d$new_cases)
plot(x=as.Date(d$date), y=d$new_cases, xlab="Date", ylab="Number of new cases", pch=1, col="red", cex=0.5)#
titletxt = paste0("Number of new cases per day in: ", country_name)#
title(titletxt)#
lines(x=as.Date(d$date), y=d$new_cases, lty="solid", lwd=2, col="red")#
# Hmm, that line has some gaps, suggesting there are some days with no data.#
# What is going on?#
unique(d$new_cases)#
#
# Let's try replacing the "NA" values with 0:#
TF = is.na(d$new_cases)#
d$new_cases[TF] = 0#
#
# And, plot again:#
plot(x=as.Date(d$date), y=d$new_cases, xlab="Date", ylab="Number of new cases", pch=1, col="red", cex=0.5)#
titletxt = paste0("Number of new cases per day in: ", country_name)#
title(titletxt)#
lines(x=as.Date(d$date), y=d$new_cases, lty="solid", lwd=2, col="red")
TF = data$location == country_name#
d2 = data[TF, ]#
TF = is.na(d2$new_cases)#
d2$new_cases[TF] = 0#
#
# Keep a count of active cases, and recovered cases#
active_cases = rep(0.0, times=nrow(d2))#
recovered_cases = rep(0.0, times=nrow(d2))#
#
# Here, we do a "for-loop". It will leap through every row#
# of the table, and do a calculation.#
##
# NOTE: to make a for-loop run, you have to run#
# the WHOLE thing, from the "for" to the final closing#
# bracket "}", at once!#
# #
for (i in 1:nrow(d2))#
	{#
	# Keep track of the starting row number#
	if (i <= 14)#
		{#
		startrow = 1#
		endrow = i#
		recovered_cases[i] = 0#
		} else {#
		startrow = startrow + 1#
		endrow = i#
		sum_of_recovered_cases = sum(d2$new_cases[1:(startrow-1)])#
		recovered_cases[i] = sum_of_recovered_cases#
		}#
	# Add up the last 14 days of active cases#
	sum_of_active_cases_14days = sum(d2$new_cases[startrow:endrow])#
	# Store the result:#
	active_cases[i] = sum_of_active_cases_14days#
	}#
#
# Plot the active cases, AND recovered cases#
# Plot a plot of white dots (just to set the plot scale)#
xvals = c(as.Date(d$date), as.Date(d$date))#
yvals = c(active_cases, recovered_cases)#
plot(x=xvals, y=yvals, xlab="Date", ylab="Number of cases", pch=".", col="white", cex=0.5)#
titletxt = paste0("Number of active & recovered cases in: ", country_name)#
title(titletxt)
points(x=as.Date(d$date), y=active_cases, pch=1, col="red", cex=0.6)#
lines(x=as.Date(d$date), y=active_cases, lty="solid", lwd=2, col="red2")#
#
# Add points & line for recovered cases#
points(x=as.Date(d$date), y=recovered_cases, pch=2, col="green3", cex=0.5)#
lines(x=as.Date(d$date), y=recovered_cases, lty="solid", lwd=2, col="green4")#
#
# Add vertical line with abline, and text, for Level 4 lockdown start#
lockdown_time = as.Date("2020-03-26")#
abline(v=lockdown_time, col="black", lty="dashed", lwd=2)#
text(x=lockdown_time, y=0.99*max(yvals), labels="lockdown begins", pos=2, srt=90, cex=0.7)#
#
# Add vertical line with abline, and text, for Level 4 lockdown end#
lockdown_time = as.Date("2020-04-28")#
abline(v=lockdown_time, col="black", lty="dashed", lwd=2)#
text(x=lockdown_time, y=0.99*max(yvals), labels="lockdown ends", pos=2, srt=90, cex=0.7)#
# Add horizontal line with abline#
threshold = 1000#
abline(h=threshold, col="grey", lty="dotted", lwd=2)#
text_x = min(xvals) + 0.05*(max(xvals) - min(xvals))#
text(x=text_x, y=threshold, labels="(1000 cases)", pos=3, srt=0, cex=0.7, col="grey")#
#
# Add legend#
legend(x="right", legend=c("active cases", "recovered"), col=c("red2", "green4"), lwd=c(2,2), pch=c(1,2))
########################################################
# The first example plot, as a PDF#
########################################################
#
pdffn = "number_of_new_cases_NZ.pdf"  # filename of PDF#
pdf(file=pdffn, width=10, height=8)    # pdf() opens the PDF for writing - won't close until dev.off()!!!#
#
# Code for your plot#
plot(x=as.Date(d$date), y=d$new_cases, xlab="Date", ylab="Number of new cases", pch=1, col="red", cex=0.5)#
titletxt = paste0("Number of new cases per day in: ", country_name)#
title(titletxt)#
lines(x=as.Date(d$date), y=d$new_cases, lty="solid", lwd=2, col="red")#
#
dev.off()	# closes the PDF for writing; after this, new plots go to screen again#
cmdstr = paste0("open ", pdffn)  # create the command to open the PDF#
system(cmdstr)                   # open the PDF in the operating system
########################################################
# The second example plot, as a PDF#
########################################################
#
pdffn = "number_of_active_recovered_cases_NZ.pdf"  # filename of PDF#
pdf(file=pdffn, width=10, height=8)    # pdf() opens the PDF for writing - won't close until dev.off()!!!#
#
# Code for your plot#
# Plot the active cases, AND recovered cases#
# Plot a plot of white dots (just to set the plot scale)#
xvals = c(as.Date(d$date), as.Date(d$date))#
yvals = c(active_cases, recovered_cases)#
plot(x=xvals, y=yvals, xlab="Date", ylab="Number of cases", pch=".", col="white", cex=0.5)#
titletxt = paste0("Number of active & recovered cases in: ", country_name)#
title(titletxt)#
#
# Notes:#
# for help on plots, ?plot#
# for help on point characters (pch), ?points#
# for other graphical parameters (e.g. lty = line type), ?par#
#
# Add points & line for active cases#
points(x=as.Date(d$date), y=active_cases, pch=1, col="red", cex=0.6)#
lines(x=as.Date(d$date), y=active_cases, lty="solid", lwd=2, col="red2")#
#
# Add points & line for recovered cases#
points(x=as.Date(d$date), y=recovered_cases, pch=2, col="green3", cex=0.5)#
lines(x=as.Date(d$date), y=recovered_cases, lty="solid", lwd=2, col="green4")#
#
# Add vertical line with abline, and text, for Level 4 lockdown start#
lockdown_time = as.Date("2020-03-26")#
abline(v=lockdown_time, col="black", lty="dashed", lwd=2)#
text(x=lockdown_time, y=0.99*max(yvals), labels="lockdown begins", pos=2, srt=90, cex=0.7)#
#
# Add vertical line with abline, and text, for Level 4 lockdown end#
lockdown_time = as.Date("2020-04-28")#
abline(v=lockdown_time, col="black", lty="dashed", lwd=2)#
text(x=lockdown_time, y=0.99*max(yvals), labels="lockdown ends", pos=2, srt=90, cex=0.7)#
# Add horizontal line with abline#
threshold = 1000#
abline(h=threshold, col="grey", lty="dotted", lwd=2)#
text_x = min(xvals) + 0.05*(max(xvals) - min(xvals))#
text(x=text_x, y=threshold, labels="(1000 cases)", pos=3, srt=0, cex=0.7, col="grey")#
#
# Add legend#
legend(x="right", legend=c("active cases", "recovered"), col=c("red2", "green4"), lwd=c(2,2), pch=c(1,2))#
#
dev.off()	# closes the PDF for writing; after this, new plots go to screen again#
cmdstr = paste0("open ", pdffn)  # create the command to open the PDF#
system(cmdstr)                   # open the PDF in the operating system
########################################################
# WEEK 4 LAB#
########################################################
#
########################################################
# PART 1: ADVANTAGES/DISADVANTAGES OF MODELS#
########################################################
# #
# Please form groups of 2-4 people, and discuss the readings#
# (Asimov and O'Neill) for 10 minutes.  Keep two lists:#
##
# - a list of possible advantages of relying on models#
# - a list of possible disadvantages of relying on models#
##
# Then, spend 10 minutes reading these articles:#
# #
# Why outbreaks like coronavirus spread exponentially, and#
# how to "flatten the curve" (free online)#
# By Harry Stevens#
# March 14, 2020#
# https://www.washingtonpost.com/graphics/2020/world/corona-simulator/#
##
# NextStrain Covid-19 webpage:#
# https://nextstrain.org/ncov#
# #
# Now, discuss what you have heard about models in #
# connection with COVID-19, and add to your list any #
# advantages/disadvantages you see in the use of #
# epidemiological models in the science/public #
# policy/public communication arenas.#
##
# Once you have some items, go up to the whiteboard and#
# write (SHORT, i.e. 1-5 words) descriptions of the#
# most important advantages/disadvantages. If you see#
# something similar already written, just add a #
# tick-mark.#
# #
# Please also use sanitiser and/or wash your hands after#
# using the shared pen.#
##
# We will then review this as a class.#
# #
########################################################
#
########################################################
# PART 2: INTRODUCTION TO ML INFERENCE#
#########################################################
# #
# We will begin our exploration of model-based inference#
# with a very simple dataset and model.#
# #
# Many biological problems, in many different fields,#
# from ecology to epidemiology, are concerned with #
# trying to estimate the prevalence or frequency of#
# something. #
##
# For example:#
##
# - Out of 1000 ponds in a region, how many contain a#
#   particular endangered frog species?#
##
# - Out of a million people, how many are resistant#
#   to measles (due to e.g. vaccination or previous #
#   infection)?#
##
# These examples (leaving out numerous real-world#
# complexities) boil down to this: there are 2 #
# possible outcomes, and we are interested in how#
# often each outcome occurs.#
##
# Another process with 2 outcomes is coin-flipping.#
##
# Coin-flipping, and any other 2-outcome process,#
# can be described with a one-parameter model, using#
# a binomial distribution ("bi-nomial" = "two names").#
##
# (We will use coin-flipping as an example, but you can#
# mentally substitute any other binomial process if#
# you like.)#
##
# The single parameter describing a binomial process#
# is "p", the probability of one of the outcomes. The#
# probability of the other outcome is 1-p.#
##
# Because there are so many different probabilities and #
# "p" terms used in probability#
# and statistics, I will use "P_heads" - the probability#
# that a coin will produce "Heads" on a single flip - to #
# describe this parameter.#
# #
#########################################################
#
# Let's consider some coin-flip data.  #
##
# Here are 100 coin flips:#
#
coin_flips = c('H','T','H','T','H','H','T','H','H','H','T','H','H','T','T','T','T','H','H','H','H','H','H','H','H','H','H','H','H','H','H','H','H','T','T','T','H','T','T','T','H','T','T','T','H','H','H','T','T','H','H','H','T','H','H','H','T','T','H','H','H','H','H','H','H','T','T','H','H','H','H','T','T','H','H','H','T','T','H','H','H','H','H','H','T','T','T','H','H','H','H','H','H','T','H','T','H','H','T','T')#
#
# Look at the data#
coin_flips#
#
# What is your guess at "P_heads", the probability of heads?#
##
#
# In the case of binomial data, we actually have a simple #
# formula to calculate the best estimate of P_heads:#
#
# Find the heads#
heads_TF = (coin_flips == "H")#
heads_TF#
#
# Find the tails#
tails_TF = (coin_flips == "T")#
tails_TF#
#
numHeads = sum(heads_TF)#
numHeads#
#
numTails = sum(tails_TF)#
numTails#
#
numTotal = length(coin_flips)#
numTotal#
#
# Here's the formula:#
P_heads_ML_estimate = numHeads / numTotal#
P_heads_ML_estimate#
#
# Well, duh, that seems pretty obvious.  At least it would have been, if we #
# weren't thinking of coins, where we have a strong prior belief that the#
# coin is probably fair.#
#
# It turns out that this formula can be justified through a technique#
# known as Maximum Likelihood.#
##
# What does it mean to say we have a "maximum likelihood" estimate of P_heads?#
# #
# "Likelihood", in statistics, means "the probability of the data under the model"#
##
#
# Let's calculate the probability of the coin flip data under the #
# hypothesis/model that P_heads is 0.5#
#
# We'll be very inefficient, and use a for-loop, and#
# if/else statements#
#
# Loop through all 100 flips#
# Make a list of the probability of #
# each datum#
P_heads_guess = 0.5#
#
# Empty list of probabilities#
probs_list = rep(NA, times=length(coin_flips))#
probs_list#
#
for (i in 1:length(coin_flips))#
    {#
    # Print an update#
    cat("\nAnalysing coin flip #", i, "/", length(coin_flips), sep="")#
#
    # Get the current coin flip#
    coin_flip = coin_flips[i]#
#
    # If the coin flip is heads, give that datum#
    # probability P_heads_guess.#
    # If tails, give it (1-P_heads_guess)#
#
    if (coin_flip == "H")#
        {#
        probs_list[i] = P_heads_guess#
        } # End if heads#
#
    if (coin_flip == "T")        #
        {#
        probs_list[i] = (1-P_heads_guess)#
        } # End if tails#
    } # End for-loop#
#
# Look at the resulting probabilities#
probs_list#
#
# We get the probability of all the data by multiplying#
# all the probabilities, with the prod() function.#
likelihood_of_data_given_P_heads_guess1 = prod(probs_list)#
likelihood_of_data_given_P_heads_guess1#
#
# That's a pretty small number!  You'll see that it's #
# just 0.5^100:#
0.5^100#
#
# A probability of 0.5 is not small, but multiply it #
# 100 values of 0.5 together, and you get a small value.#
# That's the probability of that specific sequence of #
# heads/tails, given the hypothesis that the true#
# probability is P_heads_guess.#
#
# Let's try another parameter value:#
#
# Loop through all 100 flips#
# Make a list of the probability of #
# each datum#
P_heads_guess = 0.7#
#
# Empty list of probabilities#
probs_list = rep(NA, times=length(coin_flips))#
probs_list#
#
for (i in 1:length(coin_flips))#
    {#
    # Print an update#
    cat("\nAnalysing coin flip #", i, "/", length(coin_flips), sep="")#
#
    # Get the current coin flip#
    coin_flip = coin_flips[i]#
#
    # If the coin flip is heads, give that datum#
    # probability P_heads_guess.#
    # If tails, give it (1-P_heads_guess)#
#
    if (coin_flip == "H")#
        {#
        probs_list[i] = P_heads_guess#
        } # End if heads#
#
    if (coin_flip == "T")        #
        {#
        probs_list[i] = (1-P_heads_guess)#
        } # End if tails#
    } # End for-loop#
#
# Look at the resulting probabilities#
probs_list#
#
# We get the probability of all the data by multiplying#
# all the probabilities#
likelihood_of_data_given_P_heads_guess2 = prod(probs_list)#
likelihood_of_data_given_P_heads_guess2#
#
# We got a different likelihood. It's also very small.#
# But that's not important. What's important is, #
# how many times higher is it?#
#
likelihood_of_data_given_P_heads_guess2 / likelihood_of_data_given_P_heads_guess1#
#
# Whoa!  That's a lot higher!  This means the coin flip data is 54 times more#
# probable under the hypothesis that P_heads=0.7 than under the #
# hypothesis that P_heads=0.5.#
#
# Maximum likelihood: You can see that the BEST explanation of the data #
# would be the one with the value of P_heads that maximized the probability #
# of the data.  This would be the Maximum Likelihood solution.#
#
# We could keep copying and pasting code, but that seems annoying.  Let's make a function #
# instead:#
#
# Function that calculates the probability of coin flip data#
# given a value of P_heads_guess#
calc_prob_coin_flip_data <- function(P_heads_guess, coin_flips)#
    {#
    # Empty list of probabilities#
    probs_list = rep(NA, times=length(coin_flips))#
    probs_list#
#
    for (i in 1:length(coin_flips))#
        {#
        # Print an update#
        #cat("\nAnalysing coin flip #", i, "/", length(coin_flips), sep="")#
#
        # Get the current coin flip#
        coin_flip = coin_flips[i]#
#
        # If the coin flip is heads, give that datum#
        # probability P_heads_guess.#
        # If tails, give it (1-P_heads_guess)#
#
        if (coin_flip == "H")#
            {#
            probs_list[i] = P_heads_guess#
            } # End if heads#
#
        if (coin_flip == "T")        #
            {#
            probs_list[i] = (1-P_heads_guess)#
            } # End if tails#
        } # End for-loop#
#
    # Look at the resulting probabilities#
    probs_list#
#
    # We get the probability of all the data by multiplying#
    # all the probabilities#
    likelihood_of_data_given_P_heads_guess = prod(probs_list)#
#
    # Return result#
    return(likelihood_of_data_given_P_heads_guess)#
    }#
#
# Now, we can just use this function:#
calc_prob_coin_flip_data(P_heads_guess=0.5, coin_flips=coin_flips)#
calc_prob_coin_flip_data(P_heads_guess=0.6, coin_flips=coin_flips)#
calc_prob_coin_flip_data(P_heads_guess=0.7, coin_flips=coin_flips)#
#
# Look at that!  We did all of that work in a split-second.#
#
# In fact, we can make another for-loop, and search for the ML#
# value of P_heads by trying all of the values and plotting them.#
#
# Sequence of 50 possible values of P_heads between 0 and 1#
P_heads_values_to_try = seq(from=0, to=1, length.out=50)#
likelihoods = rep(NA, times=length(P_heads_values_to_try))#
#
for (i in 1:length(P_heads_values_to_try))#
    {#
    # Get the current guess at P_heads_guess#
    P_heads_guess = P_heads_values_to_try[i]#
#
    # Calculate likelihood of the coin flip data under#
    # this value of P_heads#
    likelihood = calc_prob_coin_flip_data(P_heads_guess=P_heads_guess, coin_flips=coin_flips)#
#
    # Store the likelihood value#
    likelihoods[i] = likelihood#
    } # End for-loop#
#
# Here are the resulting likelihoods:#
likelihoods#
#
# Let's try plotting the likelihoods to see if there's a peak#
plot(x=P_heads_values_to_try, y=likelihoods)#
lines(x=P_heads_values_to_try, y=likelihoods)#
#
# Whoa! That's quite a peak!  You can see that the likelihoods#
# vary over several orders of magnitude.#
##
# Partially because of this extreme variation, we often use the #
# log-likelihood (natural log, here) instead of the raw#
# likelihood.#
##
# (Other reasons: machines have a minimum precision, log-likelihoods#
#  can be added instead of multiplied, AIC is calculated from #
#  log-likelihood, etc.)#
##
##
log_likelihoods = log(likelihoods, base=exp(1))#
#
plot(x=P_heads_values_to_try, y=log_likelihoods)#
lines(x=P_heads_values_to_try, y=log_likelihoods)#
#
# Let's plot these together#
par(mfrow=c(2,1))#
plot(x=P_heads_values_to_try, y=likelihoods, main="Likelihood (L) of the data")#
lines(x=P_heads_values_to_try, y=likelihoods)#
#
plot(x=P_heads_values_to_try, y=log_likelihoods, main="Log-likelihood (LnL) of the data")#
lines(x=P_heads_values_to_try, y=log_likelihoods)#
#
# Maximum likelihood optimization#
# #
# You can see that the maximum likelihood of the data occurs when #
# P_heads is somewhere around 0.6 or 0.7.  What is it #
# exactly?#
##
# We could just keep trying more values until we find whatever#
# precision we desire.  But, R has a function for#
# maximum likelihood optimization!#
# #
# It's called optim().  Optim() takes a function as an input.#
# Fortunately, we've already written a function!#
##
# Let's modify our function a bit to return the log-likelihood,#
# and print the result:#
#
# Function that calculates the probability of coin flip data#
# given a value of P_heads_guess#
calc_prob_coin_flip_data2 <- function(P_heads_guess, coin_flips)#
    {#
    # Empty list of probabilities#
    probs_list = rep(NA, times=length(coin_flips))#
    probs_list#
#
    for (i in 1:length(coin_flips))#
        {#
        # Print an update#
        #cat("\nAnalysing coin flip #", i, "/", length(coin_flips), sep="")#
#
        # Get the current coin flip#
        coin_flip = coin_flips[i]#
#
        # If the coin flip is heads, give that datum#
        # probability P_heads_guess.#
        # If tails, give it (1-P_heads_guess)#
#
        if (coin_flip == "H")#
            {#
            probs_list[i] = P_heads_guess#
            } # End if heads#
#
        if (coin_flip == "T")        #
            {#
            probs_list[i] = (1-P_heads_guess)#
            } # End if tails#
        } # End for-loop#
#
    # Look at the resulting probabilities#
    probs_list#
#
    # We get the probability of all the data by multiplying#
    # all the probabilities#
    likelihood_of_data_given_P_heads_guess = prod(probs_list)#
#
    # Get the log-likelihood#
    LnL = log(likelihood_of_data_given_P_heads_guess)#
    LnL#
#
    # Error correction: if -Inf, reset to a low value#
    if (is.finite(LnL) == FALSE)#
        {#
        LnL = -1000#
        }#
#
    # Print some output#
    print_txt = paste("\nWhen P_heads=", P_heads_guess, ", LnL=", LnL, sep="")#
    cat(print_txt)#
#
    # Return result#
    return(LnL)#
    }#
#
# Try the function out:#
LnL = calc_prob_coin_flip_data2(P_heads_guess=0.1, coin_flips=coin_flips)#
LnL = calc_prob_coin_flip_data2(P_heads_guess=0.2, coin_flips=coin_flips)#
LnL = calc_prob_coin_flip_data2(P_heads_guess=0.3, coin_flips=coin_flips)#
#
# Looks like it works!  Let's use optim() to search for he #
# best P_heads value:#
#
# Set a starting value of P_heads#
starting_value = 0.1#
#
# Set the limits of the search#
limit_bottom = 0#
limit_top = 1#
#
optim_result = optim(par=starting_value, fn=calc_prob_coin_flip_data2, coin_flips=coin_flips, method="L-BFGS-B", lower=limit_bottom, upper=limit_top, control=list(fnscale=-1))#
#
# You can see the search print out as it proceeds.#
#
# Let's see what ML search decided on:#
optim_result#
#
# Let's compare the LnL from ML search, with the binomial mean#
optim_result$par#
#
# Here's the formula:#
P_heads_ML_estimate = numHeads / numTotal#
P_heads_ML_estimate
rnorm(n=1, mean=6, sd=1)#
rnorm(n=1, mean=6, sd=1)#
rnorm(n=1, mean=6, sd=1)#
#
set.seed(54321)#
rnorm(n=1, mean=6, sd=1)#
rnorm(n=1, mean=6, sd=1)#
#
set.seed(54321)#
rnorm(n=1, mean=6, sd=1)#
rnorm(n=1, mean=6, sd=1)#
#
set.seed(54321)#
rnorm(n=1, mean=6, sd=1)#
rnorm(n=1, mean=6, sd=1)
33-19
library(deSolve)#
#
likelihood_single_point <- function(data.point, model.point, log=TRUE)#
	{#
	# Get the probability density of the count, assuming#
	# the observed count is a poisson process with an #
	# average value matching the true process.#
	##
	# This allows for variation, e.g. if a case is reported #
	# days after it occurs.#
	likelihood = dpois(x=data.point, lambda=model.point, log=log)	#
	# Return the likelihood value#
	return(likelihood)#
	} # END of likelihood_single_point#
#
likelihood_time_series <- function(data.points, model.points, log=TRUE)#
	{#
	# Error check - return a stop() message if check fails#
	if (length(data.points) != length(model.points))#
		{ stop("ERROR in likelihood_time_series(): the lengths of data.points and model.points must match.") }#
	# Calculate the likelihoods of the data.points#
	likelihoods = mapply(FUN=likelihood_single_point, data.point=data.points, model.point=model.points, MoreArgs=list(log=log))#
	# If you calculated log-likelihoods, then sum them#
	# If you calculated raw likelihoods, then multiply them#
	if (log == TRUE)#
		{#
		total_likelihood = sum(likelihoods)#
		} else {#
		total_likelihood = prod(likelihoods)  # prod=take the product#
		} # END if/else statement: if (log == TRUE)#
	# Return that value#
	return (total_likelihood)#
	} # END of likelihood_time_series#
#
########################################################
# Functions for drawing an SIR curve from given parameters#
########################################################
library(deSolve)#
SIR_ode <- function(time, state, parameters)#
	{#
	# The above inputs are:#
	# time = a time point#
	# state = an R list of the 3 state values, i.e. the #
	#         population sizes of S, I, and R#
	# parameters = an R list of the parameters R0 and D_inf#
	# Convert the input parameters "R0" and "D_inf" #
	# into the rates "beta" and "nu"#
	beta <- parameters[["R0"]] / parameters[["D_inf"]]#
	nu <- 1 / parameters[["D_inf"]]#
#
	# Extract the current values of the states S, I, and R#
	S <- state[["S"]]#
	I <- state[["I"]]#
	R <- state[["R"]]#
#
	# Calculate N, the total of S+I+R, #
	# i.e. the population size#
	N <- S + I + R#
	# Write out the system of #
	# Ordinary Differential Equations (ODEs)#
	dS <- -beta * I/N * S #
	dI <- beta * I/N * S - nu * I#
	dR <- nu * I#
	# Return the current rates of change of S, I, and R:#
	return(list(c(dS, dI, dR)))#
	} # End of function SIR_ode#
#
simulate_SIR <- function(theta, init.state, times)#
	{#
	trajectory <- data.frame(ode(y = init.state,#
                times = times,#
                func = SIR_ode,#
                parms = theta,#
                method = "ode45"))#
	return(trajectory)#
	} # End of simulate_SIR()#
#
simulate_SIR_changes <- function(thetas_states_df, times)#
	{#
	# Loop through the rows#
	trajectory = NULL#
	for (rn in 1:nrow(thetas_states_df))#
		{#
		if (rn == 1)#
			{#
			init.state = c(S=thetas_states_df$S[rn], I=thetas_states_df$I[rn], R=thetas_states_df$R[rn])#
			theta = list(R0=thetas_states_df$R0[rn], D_inf=thetas_states_df$D_inf[rn])#
			} else {#
			last_row = trajectory[nrow(trajectory),]#
			init.state = c(S=last_row$S+thetas_states_df$S[rn], I=last_row$I+thetas_states_df$I[rn], R=last_row$R+thetas_states_df$R[rn])#
			theta = list(R0=thetas_states_df$R0[rn], D_inf=thetas_states_df$D_inf[rn])			#
			}#
		# Read in the parameters for the initial, versus later, time-bins#
		if (rn >= nrow(thetas_states_df))#
			{#
			start_time = thetas_states_df$time[rn]#
			end_time = max(times)#
			} else {#
			start_time = thetas_states_df$time[rn]#
			end_time = thetas_states_df$time[rn+1]#
			}#
		TF1 = times >= start_time#
		TF2 = times <= end_time#
		TF = (TF1 + TF2) == 2#
		tmp_times = times[TF]#
#
		tmp_trajectory = simulate_SIR(theta=theta, init.state=init.state, times=tmp_times)#
		if (rn == 1)#
			{#
			trajectory = rbind(trajectory, tmp_trajectory)#
			} else {#
			trajectory_minus_last_state = trajectory[-nrow(trajectory),]#
			trajectory = rbind(trajectory_minus_last_state, tmp_trajectory)#
			} # if (rn == 1)#
		} # END for (rn in 1:nrow(thetas_states_df))#
	return(trajectory)#
	} # End simulate_SIR_changes()#
# Function definition for params_to_likelihood_v1#
params_to_likelihood_v1 <- function(params, data.points, thetas_states_df, delay_val=0.0, printvals=TRUE, makePlots=FALSE)#
	{#
	if (nrow(thetas_states_df) < 2)#
		{#
		txt = "STOP ERROR in params_to_likelihood_v1(): Your input parameters table, 'thetas_states_df', must have 2 or more rows in it. Check you thetas_states_df input, and try again."#
		stop(txt)#
		}#
	# The times are just the length of the data.points#
	times = 1:length(data.points)#
#
	# (1) input the free parameters#
	thetas_states_temp = thetas_states_df#
	TF = thetas_states_temp == "free"#
	thetas_states_temp[TF] = params#
	# Ensure everything is numeric#
	thetas_states_temp$time = as.numeric(thetas_states_temp$time)#
	thetas_states_temp$R0 = as.numeric(thetas_states_temp$R0)#
	thetas_states_temp$D_inf = as.numeric(thetas_states_temp$D_inf)#
	thetas_states_temp$S = as.numeric(thetas_states_temp$S)#
	thetas_states_temp$I = as.numeric(thetas_states_temp$I)#
	thetas_states_temp$R = as.numeric(thetas_states_temp$R)#
	# You have to round the "time" variable to the nearest day#
	thetas_states_temp$time = round(thetas_states_temp$time, digits=0)#
	# Error checks, e.g. for "time" values out of order,#
	# "time" outside of min/max#
	time_inputs_valid = TRUE#
	for (i in 2:length(thetas_states_temp$time))#
		{#
		if (thetas_states_temp$time[i] <= thetas_states_temp$time[i-1])#
			{#
			time_inputs_valid = FALSE#
			break()#
			}#
		if (thetas_states_temp$time[i-1] < times[1])#
			{#
			time_inputs_valid = FALSE#
			break()			#
			}#
		if (thetas_states_temp$time[i-1] > times[length(times)])#
			{#
			time_inputs_valid = FALSE#
			break()			#
			}#
		if (thetas_states_temp$time[i] < times[1])#
			{#
			time_inputs_valid = FALSE#
			break()			#
			}#
		if (thetas_states_temp$time[i] > times[length(times)])#
			{#
			time_inputs_valid = FALSE#
			break()			#
			}#
		}#
	# If any of time inputs are invalid, return an absurdly low lnL#
	if (time_inputs_valid== FALSE)#
		{#
		lnL=-1e100#
#
		# Print, if desired#
		if (printvals == TRUE)#
			{#
			print(thetas_states_temp)#
			cat("log-likelihood = ", lnL, "\n", sep="")#
			}#
#
		return(lnL)#
		}#
	# Error check#
	if ((max(thetas_states_temp$time)+delay_val) > max(times))#
		{#
		stop("ERROR in params_to_likelihood_v1: there is a 'thetas_states_df$time'+delay_val greater than found in 'times'")#
		}#
	# Make sure everything in thetas_states_df is numeric, instead of character#
	for (i in 1:ncol(thetas_states_temp))#
		{#
		thetas_states_temp[,i] = as.numeric(thetas_states_temp[,i])#
		}#
	# Ad2 the delay (allows time for interventions to show up#
	# in the detections)#
	thetas_states_temp$time[2:length(thetas_states_temp$time)] = thetas_states_temp$time[2:length(thetas_states_temp$time)]#
	# Calculate the trajectory given the parameters, #
	# input into model.points#
	trajectory = simulate_SIR_changes(thetas_states_df=thetas_states_temp, times)#
	model.points = trajectory$I#
	lnL = likelihood_time_series(data.points, model.points, log=TRUE)#
	if (is.finite(lnL)== FALSE)#
		{#
		lnL=-1e100#
		}#
	# Print, if desired#
	if (printvals == TRUE)#
		{#
		print(thetas_states_temp)#
		cat("log-likelihood = ", lnL, "\n", sep="")#
		}#
	# Make plots, if desired#
	if (makePlots == TRUE)#
		{#
		plot_trajectory_lines(trajectory, theta=NULL, thetas_states_df=thetas_states_df, title_prefix="Plot #5:")#
		}#
	return(lnL)#
	} # END params_to_likelihood_v1#
#
########################################################
# FINISHED LOADING OUR FUNCTIONS FOR SIR SIMULATION AND INFERENCE#
########################################################
########################################################
# LOAD & PROCESS DATA FROM OURWORLDINDATA#
########################################################
#
# Function to help plot your country's data#
# This function does the data-processing we did in the first week:#
# (1) converts "NA" values to 0.0#
# (2) adds up the total number of recovered and active #
#     cases each day.#
calc_active_recovered_cases <- function(d2, add_zeros_back_to=as.Date("2019-12-31"))#
	{#
	# Subset to your country, replace "NA" values with 0:#
	TF = is.na(d2$new_cases)#
	d2$new_cases[TF] = 0#
#
	# Keep a count of active cases, and recovered cases#
	active_cases = rep(0.0, times=nrow(d2))#
	recovered_cases = rep(0.0, times=nrow(d2))#
#
	# Here, we do a "for-loop". It will leap through every row#
	# of the table, and do a calculation.#
	##
	# NOTE: to make a for-loop run, you have to run#
	# the WHOLE thing, from the "for" to the final closing#
	# bracket "}", at once!#
	# #
	for (i in 1:nrow(d2))#
		{#
		# Keep track of the starting row number#
		if (i <= 14)#
			{#
			startrow = 1#
			endrow = i#
			recovered_cases[i] = 0#
			} else {#
			startrow = startrow + 1#
			endrow = i#
			sum_of_recovered_cases = sum(d2$new_cases[1:(startrow-1)])#
			recovered_cases[i] = sum_of_recovered_cases#
			} # END if/else statement#
		# Add up the last 14 days of active cases#
		sum_of_active_cases_14days = sum(d2$new_cases[startrow:endrow])#
		# Store the result:#
		active_cases[i] = sum_of_active_cases_14days#
		} # END for (i in 1:nrow(d2))#
	d3 = cbind(d2, active_cases, recovered_cases)#
	# Add 0s back to 2019-12-31 (like the original OurWorldInData had it)#
	zero_row = d3[1,]#
	zero_row$active_cases = 0#
	zero_row$recovered_cases = 0#
	d3_with_zero_rows_df = d3#
	orig_starting_day = as.Date(zero_row$date)#
	current_day = orig_starting_day-1#
	if (is.na(add_zeros_back_to) == FALSE)#
		{#
		if (as.Date(d3$date[1]) > as.Date(add_zeros_back_to))#
			{#
			days_to_add = as.numeric(as.Date(d3$date[1]) - as.Date(add_zeros_back_to))#
			for (j in 1:days_to_add)#
				{#
				zero_row$date = current_day#
				d3_with_zero_rows_df = rbind(zero_row, d3_with_zero_rows_df)#
				current_day = current_day - 1#
				}#
			}#
		return(d3_with_zero_rows_df)#
		}#
	return(d3)#
	} # END calc_active_recovered_cases <- function(d2)#
# Load ODE-solving library#
library(deSolve)#
#
# Data setup#
fn = "https://covid.ourworldindata.org/data/owid-covid-data.csv"#
data = read.csv(file=fn)#
country_name = "New Zealand"#
TF = data$location == country_name#
d2 = data[TF, ]#
d3 = calc_active_recovered_cases(d2)#
#
# Plot the data:#
plot(x=as.Date(d3$date), y=d3$active_cases, xlab="Date", ylab="Active cases", col="red", pch="+")#
titletxt = paste0("Active COVID-19 cases in ", country_name, "\n(from OurWorldInData)")#
title(titletxt)#
points(x=as.Date(d3$date), y=d3$recovered, col="green3")#
# Note: this script was written in August 2020, when NZ#
# had a small 2nd wave of Covid. Since then, virtually#
# all of NZ's Covid cases have been travelers in #
# Managed Isolation/Quarantine. Modeling cases that are #
# not local transmission is pretty pointless with an #
# SIR model, so I am cutting the data off at August 30, 2020.#
##
# You may do this, or not, with your own data, depending#
# on what seems relevant.#
# #
# Cutting the data after a date#
dim(calc_active_recovered_cases(d2))#
maximum_date = as.Date("2020-08-30")#
TF = as.Date(calc_active_recovered_cases(d2)$date) < maximum_date  # TF = TRUE/FALSE result#
d3 = calc_active_recovered_cases(d2)[TF,]  # this takes just the rows where TF=TRUE#
dim(d3)#
#
# Plot the data:#
plot(x=as.Date(d3$date), y=d3$active_cases, xlab="Date", ylab="Active cases", col="red", pch="+")#
titletxt = paste0("Active COVID-19 cases in ", country_name, "\n(from OurWorldInData)")#
title(titletxt)#
points(x=as.Date(d3$date), y=d3$recovered, col="green3")
########################################################
# Six models of New Zealand's epidemic#
########################################################
#
########################################################
# Model 1: A 2-regime model, with R0 fixed to 3.0#
########################################################
times = 1:nrow(d3)      # Number of days since first day#
#
# Set up regimes:#
# NZ Level 4 lockdown went in on March 26:#
# March 26 = Day 87, +1 for 31/21/2019, +8 for delay to see lockdown effect = 96#
# Allowing an earlier pre-lockdown slowdown due to social distancing & public health = 85#
# Allowing an uptick in July (in real life, these are imported cases)#
case1 = (1:nrow(d3))[d3$active_cases>0][1] # day of the first detected case#
time = c(1, case1) #
R0 = c(0.0, 2.7)    # initial guesses#
D_inf = c(8.0, 8.0) # seems to fit data#
S = c(as.numeric(d3$population[1]), 0) # putting in the country's population size#
I = c(0, 1) # the number of cases on day 1 is a "nuisance parameter"#
R = c(0, 0) # no vaccinations#
thetas_states_table = cbind(time, R0, D_inf, S, I, R)#
thetas_states_df = as.data.frame(thetas_states_table, stringsAsFactors=FALSE)#
thetas_states_df#
#
# Make some parameters into "free" parameters, to be inferred#
thetas_states_df$R0[2] = "free"#
thetas_states_df#
#
# Run the params_to_likelihood_v1() function once, to see your starting likelihood#
data.points = d3$active_cases#
params = thetas_states_table[thetas_states_df=="free"] # starting parameter values#
lnL_result = params_to_likelihood_v1(params, data.points, thetas_states_df, delay_val=0, printvals=TRUE, makePlots=FALSE)#
lnL_result#
#
# Graphing the model model#
thetas_states_ML = thetas_states_df#
TF = thetas_states_ML == "free"#
thetas_states_ML[TF] = thetas_states_table[TF]#
# Conver to numeric#
for (i in 1:ncol(thetas_states_ML))#
	{ thetas_states_ML[,i] = as.numeric(thetas_states_ML[,i]) }#
#
# Plot the results#
trajectory = simulate_SIR_changes(thetas_states_df=thetas_states_ML, times=times)#
maxy = max(max(trajectory$I), max(data.points))#
xvals = c(trajectory$time, times)#
yvals = c(trajectory$I, data.points) + 0.1 # Adding +0.1 to prevent y-axis error with log(0)#
plot(x=xvals, y=yvals, pch=".", col="white", xlim=c(0, max(trajectory$time)), ylim=c(0.1, maxy), xlab="Day", ylab="Number of individuals (log scale)", log="y")#
lines(x=trajectory$time, y=trajectory$I, lwd=3, col="firebrick2")#
points(times, data.points, col="red", pch="+")#
legend(x="topleft", legend=c("Active COVID-19 case count", 'ML-fitted projection of "I" (Infected)'), lty=c("blank", "solid"), lwd=c(1,3), pch=c("+", "."), col=c("red","firebrick2"), cex=0.8)#
#
titletxt = paste0("ML fit, active cases from: ", country_name, "\nM1 (a 2-regime model, R0 fixed to 2.7); max lnL=", round(lnL_result, 2))#
title(titletxt)#
# Save this model's parameters and log-likelihood#
thetas_states_ML_model1 = thetas_states_ML#
total_lnL_Model1 = lnL_result
times = 1:nrow(d3)      # Number of days since first day#
#
# Set up regimes:#
case1 = (1:nrow(d3))[d3$active_cases>0][1] # day of the first detected case#
time = c(1, case1) #
R0 = c(0.0, 3.0)    # initial guesses#
D_inf = c(8.0, 8.0) # seems to fit data#
S = c(as.numeric(d3$population[1]), 0) # putting in the country's population size#
I = c(0, 1) # the number of cases on day 1 is a "nuisance parameter"#
R = c(0, 0) # no vaccinations#
thetas_states_table = cbind(time, R0, D_inf, S, I, R)#
thetas_states_df = as.data.frame(thetas_states_table, stringsAsFactors=FALSE)#
thetas_states_df#
#
# Make some parameters into "free" parameters, to be inferred#
thetas_states_df$R0[2] = "free"#
thetas_states_df#
#
# Run the params_to_likelihood_v1() function once, to see your starting likelihood#
data.points = d3$active_cases#
params = thetas_states_table[thetas_states_df=="free"] # starting parameter values#
params_to_likelihood_v1(params, data.points, thetas_states_df, delay_val=0, printvals=TRUE, makePlots=FALSE)#
#
# Running the Maximum Likelihood search with the optim() function.#
# LOOK AT THE OUTPUT THAT PRINTS TO SCREEN!!#
ML_results = optim(par=params, fn=params_to_likelihood_v1, data.points=data.points, thetas_states_df=thetas_states_df, delay_val=0, printvals=TRUE, method="L-BFGS-B", lower=0.0, control=list(fnscale=-1))#
#
# Graphing the ML model#
# Take the learned parameters from "ML_results", put them#
# into a theta_states data.frame for simulation and plotting#
thetas_states_ML = thetas_states_df#
TF = thetas_states_ML == "free"#
thetas_states_ML[TF] = ML_results$par#
for (i in 1:ncol(thetas_states_ML))#
	{ thetas_states_ML[,i] = as.numeric(thetas_states_ML[,i]) }#
thetas_states_ML$time[2:length(thetas_states_ML$time)] = thetas_states_ML$time[2:length(thetas_states_ML$time)]#
# Plot the results#
trajectory = simulate_SIR_changes(thetas_states_df=thetas_states_ML, times=times)#
maxy = max(max(trajectory$I), max(data.points))#
xvals = c(trajectory$time, times)#
yvals = c(trajectory$I, data.points)#
plot(x=xvals, y=yvals, pch=".", col="white", xlim=c(0, max(trajectory$time)), ylim=c(0, maxy), xlab="Day", ylab="Number of individuals")#
lines(x=trajectory$time, y=trajectory$I, lwd=3, col="firebrick2")#
points(times, data.points, col="red", pch="+")#
legend(x="topleft", legend=c("Active COVID-19 case count", 'ML-fitted projection of "I" (Infected)'), lty=c("blank", "solid"), lwd=c(1,3), pch=c("+", "."), col=c("red","firebrick2"), cex=0.8)#
#
titletxt = paste0("ML fit, active cases from: ", country_name, "\nM2 (a 2-regime, 1 parameter model), max lnL = ", round(ML_results$value, 2))#
title(titletxt)#
# Save this model's parameters and log-likelihood#
thetas_states_ML_model2 = thetas_states_ML#
total_lnL_Model2 = ML_results$value
########################################################
# Model M3: A 3-regime model (3 free parameters)#
########################################################
times = 1:nrow(d3)      # Number of days since first day#
#
# Set up regimes:#
# NZ Level 4 lockdown went in on March 26:#
# March 26 = Day 87, +1 for 31/21/2019, +8 for delay to see lockdown effect = 96#
case1 = (1:nrow(d3))[d3$active_cases>0][1] # day of the first detected case#
time = c(1, case1, 96) #
R0 = c(0.0, 3.0, 0.3)    # initial guesses#
D_inf = c(8.0, 8.0, 8.0) # seems to fit data#
S = c(as.numeric(d3$population[1]), 0, 0) # putting in the country's population size#
I = c(0, 1, 0) # the number of cases on day 1 is a "nuisance parameter"#
R = c(0, 0, 0) # no vaccinations#
thetas_states_table = cbind(time, R0, D_inf, S, I, R)#
thetas_states_df = as.data.frame(thetas_states_table, stringsAsFactors=FALSE)#
thetas_states_df#
#
# Make some parameters into "free" parameters, to be inferred#
thetas_states_df$I[2] = "free"#
thetas_states_df$R0[2] = "free"#
thetas_states_df$R0[3] = "free"#
thetas_states_df#
#
# Run the params_to_likelihood_v1() function once, to see your starting likelihood#
data.points = d3$active_cases#
params = thetas_states_table[thetas_states_df=="free"] # starting parameter values#
params_to_likelihood_v1(params, data.points, thetas_states_df, delay_val=0, printvals=TRUE, makePlots=FALSE)#
#
# Running the Maximum Likelihood search with the optim() function.#
# LOOK AT THE OUTPUT THAT PRINTS TO SCREEN!!#
ML_results = optim(par=params, fn=params_to_likelihood_v1, data.points=data.points, thetas_states_df=thetas_states_df, delay_val=0, printvals=TRUE, method="L-BFGS-B", lower=0.0, control=list(fnscale=-1))#
#
# Graphing the ML model#
# Take the learned parameters from "ML_results", put them#
# into a theta_states data.frame for simulation and plotting#
thetas_states_ML = thetas_states_df#
TF = thetas_states_ML == "free"#
thetas_states_ML[TF] = ML_results$par#
for (i in 1:ncol(thetas_states_ML))#
	{ thetas_states_ML[,i] = as.numeric(thetas_states_ML[,i]) }#
thetas_states_ML$time[2:length(thetas_states_ML$time)] = thetas_states_ML$time[2:length(thetas_states_ML$time)]#
# Plot the results#
trajectory = simulate_SIR_changes(thetas_states_df=thetas_states_ML, times=times)#
maxy = max(max(trajectory$I), max(data.points))#
xvals = c(trajectory$time, times)#
yvals = c(trajectory$I, data.points)#
plot(x=xvals, y=yvals, pch=".", col="white", xlim=c(0, max(trajectory$time)), ylim=c(0, maxy), xlab="Day", ylab="Number of individuals")#
lines(x=trajectory$time, y=trajectory$I, lwd=3, col="firebrick2")#
points(times, data.points, col="red", pch="+")#
legend(x="topleft", legend=c("Active COVID-19 case count", 'ML-fitted projection of "I" (Infected)'), lty=c("blank", "solid"), lwd=c(1,3), pch=c("+", "."), col=c("red","firebrick2"), cex=0.8)#
#
titletxt = paste0("ML fit, active cases from: ", country_name, "\nM3 (a 3-regime, 3 param model), max lnL = ", round(ML_results$value, 2))#
title(titletxt)#
# Save this model's parameters and log-likelihood#
thetas_states_ML_model3 = thetas_states_ML#
total_lnL_Model3 = ML_results$value
########################################################
# Model 4: A 4-regime model (4 free parameters)#
########################################################
times = 1:nrow(d3)      # Number of days since first day#
#
# Set up regimes:#
# NZ Level 4 lockdown went in on March 26:#
# March 26 = Day 87, +1 for 31/21/2019, +8 for delay to see lockdown effect = 96#
# Allowing an uptick in July (in real life, these are imported cases) = 140#
case1 = (1:nrow(d3))[d3$active_cases>0][1] # day of the first detected case#
time = c(1, case1, 96, 140) #
R0 = c(0.0, 3.0, 0.3, 1.5)    # initial guesses#
D_inf = c(8.0, 8.0, 8.0, 8.0) # seems to fit data#
S = c(as.numeric(d3$population[1]), 0, 0, 0) # putting in the country's population size#
I = c(0, 1, 0, 0) # the number of cases on day 1 is a "nuisance parameter"#
R = c(0, 0, 0, 0) # no vaccinations#
thetas_states_table = cbind(time, R0, D_inf, S, I, R)#
thetas_states_df = as.data.frame(thetas_states_table, stringsAsFactors=FALSE)#
thetas_states_df#
#
# Make some parameters into "free" parameters, to be inferred#
thetas_states_df$I[2] = "free"#
thetas_states_df$R0[2] = "free"#
thetas_states_df$R0[3] = "free"#
thetas_states_df$R0[4] = "free"#
thetas_states_df#
#
# Run the params_to_likelihood_v1() function once, to see your starting likelihood#
data.points = d3$active_cases#
params = thetas_states_table[thetas_states_df=="free"] # starting parameter values#
params_to_likelihood_v1(params, data.points, thetas_states_df, delay_val=0, printvals=TRUE, makePlots=FALSE)#
#
# Running the Maximum Likelihood search with the optim() function.#
# LOOK AT THE OUTPUT THAT PRINTS TO SCREEN!!#
ML_results = optim(par=params, fn=params_to_likelihood_v1, data.points=data.points, thetas_states_df=thetas_states_df, delay_val=0, printvals=TRUE, method="L-BFGS-B", lower=0.0, control=list(fnscale=-1))#
#
# Graphing the ML model#
# Take the learned parameters from "ML_results", put them#
# into a theta_states data.frame for simulation and plotting#
thetas_states_ML = thetas_states_df#
TF = thetas_states_ML == "free"#
thetas_states_ML[TF] = ML_results$par#
for (i in 1:ncol(thetas_states_ML))#
	{ thetas_states_ML[,i] = as.numeric(thetas_states_ML[,i]) }#
thetas_states_ML$time[2:length(thetas_states_ML$time)] = thetas_states_ML$time[2:length(thetas_states_ML$time)]#
# Plot the results#
trajectory = simulate_SIR_changes(thetas_states_df=thetas_states_ML, times=times)#
maxy = max(max(trajectory$I), max(data.points))#
xvals = c(trajectory$time, times)#
yvals = c(trajectory$I, data.points)#
plot(x=xvals, y=yvals, pch=".", col="white", xlim=c(0, max(trajectory$time)), ylim=c(0, maxy), xlab="Day", ylab="Number of individuals")#
lines(x=trajectory$time, y=trajectory$I, lwd=3, col="firebrick2")#
points(times, data.points, col="red", pch="+")#
legend(x="topleft", legend=c("Active COVID-19 case count", 'ML-fitted projection of "I" (Infected)'), lty=c("blank", "solid"), lwd=c(1,3), pch=c("+", "."), col=c("red","firebrick2"), cex=0.8)#
#
titletxt = paste0("ML fit, active cases from: ", country_name, "\nM4 (a 4-regime model, 4 free params) max lnL = ", round(ML_results$value, 2))#
title(titletxt)#
# Save this model's parameters and log-likelihood#
thetas_states_ML_model4 = thetas_states_ML#
total_lnL_Model4 = ML_results$value
########################################################
# Model M5: A 5-regime model, 5 free parameters#
########################################################
times = 1:nrow(d3)      # Number of days since first day#
#
# Set up regimes:#
# NZ Level 4 lockdown went in on March 26:#
# March 26 = Day 87, +1 for 31/21/2019, +8 for delay to see lockdown effect = 96#
# Allowing an earlier pre-lockdown slowdown due to social distancing & public health = 85#
# Allowing an uptick in July (in real life, these are imported cases) = 140#
case1 = (1:nrow(d3))[d3$active_cases>0][1] # day of the first detected case#
time = c(1, case1, 85, 96, 140) #
R0 = c(0.0, 3.0, 1.5, 0.3, 1.5)    # initial guesses#
D_inf = c(8.0, 8.0, 8.0, 8.0, 8.0) # seems to fit data#
S = c(as.numeric(d3$population[1]), 0, 0, 0, 0) # putting in the country's population size#
I = c(0, 1, 0, 0, 0) # the number of cases on day 1 is a "nuisance parameter"#
R = c(0, 0, 0, 0, 0) # no vaccinations#
thetas_states_table = cbind(time, R0, D_inf, S, I, R)#
thetas_states_df = as.data.frame(thetas_states_table, stringsAsFactors=FALSE)#
thetas_states_df#
#
# Make some parameters into "free" parameters, to be inferred#
thetas_states_df$I[2] = "free"#
thetas_states_df$R0[2] = "free"#
thetas_states_df$R0[3] = "free"#
thetas_states_df$R0[4] = "free"#
thetas_states_df$R0[5] = "free"#
thetas_states_df#
#
# Run the params_to_likelihood_v1() function once, to see your starting likelihood#
data.points = d3$active_cases#
params = thetas_states_table[thetas_states_df=="free"] # starting parameter values#
params_to_likelihood_v1(params, data.points, thetas_states_df, delay_val=0, printvals=TRUE, makePlots=FALSE)#
#
# Running the Maximum Likelihood search with the optim() function.#
# LOOK AT THE OUTPUT THAT PRINTS TO SCREEN!!#
ML_results = optim(par=params, fn=params_to_likelihood_v1, data.points=data.points, thetas_states_df=thetas_states_df, delay_val=0, printvals=TRUE, method="L-BFGS-B", lower=0.0, control=list(fnscale=-1))#
#
# Graphing the ML model#
# Take the learned parameters from "ML_results", put them#
# into a theta_states data.frame for simulation and plotting#
thetas_states_ML = thetas_states_df#
TF = thetas_states_ML == "free"#
thetas_states_ML[TF] = ML_results$par#
for (i in 1:ncol(thetas_states_ML))#
	{ thetas_states_ML[,i] = as.numeric(thetas_states_ML[,i]) }#
thetas_states_ML$time[2:length(thetas_states_ML$time)] = thetas_states_ML$time[2:length(thetas_states_ML$time)]#
# Plot the results#
trajectory = simulate_SIR_changes(thetas_states_df=thetas_states_ML, times=times)#
maxy = max(max(trajectory$I), max(data.points))#
xvals = c(trajectory$time, times)#
yvals = c(trajectory$I, data.points)#
plot(x=xvals, y=yvals, pch=".", col="white", xlim=c(0, max(trajectory$time)), ylim=c(0, maxy), xlab="Day", ylab="Number of individuals")#
lines(x=trajectory$time, y=trajectory$I, lwd=3, col="firebrick2")#
points(times, data.points, col="red", pch="+")#
legend(x="topleft", legend=c("Active COVID-19 case count", 'ML-fitted projection of "I" (Infected)'), lty=c("blank", "solid"), lwd=c(1,3), pch=c("+", "."), col=c("red","firebrick2"), cex=0.8)#
#
titletxt = paste0("ML fit, active cases from: ", country_name, "\nM5 (a 5-regime, 5 param model) max lnL = ", round(ML_results$value, 2))#
title(titletxt)#
#
# Save this model's parameters and log-likelihood#
thetas_states_ML_model5 = thetas_states_ML#
total_lnL_Model5 = ML_results$value
########################################################
# Model M6: A 6-regime model, 6 free parameters#
########################################################
times = 1:nrow(d3)      # Number of days since first day#
#
# Set up regimes:#
# NZ Level 4 lockdown went in on March 26:#
# March 26 = Day 87, +1 for 31/21/2019, +8 for delay to see lockdown effect = 96#
# Allowing an earlier pre-lockdown slowdown due to social distancing & public health = 85#
# Allowing an earlier pre-lockdown slowdown due to social distancing & public health = 85#
# Allowing an uptick in July (in real life, these are imported cases) = 140#
case1 = (1:nrow(d3))[d3$active_cases>0][1] # day of the first detected case#
time = c(1, case1, 85, 94, 96, 140) #
R0 = c(0.0, 3.0, 1.5, 1.5, 0.3, 1.5)    # initial guesses#
D_inf = c(8.0, 8.0, 8.0, 8.0, 8.0, 8.0) # seems to fit data#
S = c(as.numeric(d3$population[1]), 0, 0, 0, 0, 0) # putting in the country's population size#
I = c(0, 1, 0, 0, 0, 0) # the number of cases on day 1 is a "nuisance parameter"#
R = c(0, 0, 0, 0, 0, 0) # no vaccinations#
thetas_states_table = cbind(time, R0, D_inf, S, I, R)#
thetas_states_df = as.data.frame(thetas_states_table, stringsAsFactors=FALSE)#
thetas_states_df#
#
# Make some parameters into "free" parameters, to be inferred#
thetas_states_df$I[2] = "free"#
thetas_states_df$R0[2] = "free"#
thetas_states_df$R0[3] = "free"#
thetas_states_df$R0[4] = "free"#
thetas_states_df$R0[5] = "free"#
thetas_states_df$R0[6] = "free"#
thetas_states_df#
#
# Run the params_to_likelihood_v1() function once, to see your starting likelihood#
data.points = d3$active_cases#
params = thetas_states_table[thetas_states_df=="free"] # starting parameter values#
params_to_likelihood_v1(params, data.points, thetas_states_df, delay_val=0, printvals=TRUE, makePlots=FALSE)#
#
# Running the Maximum Likelihood search with the optim() function.#
# LOOK AT THE OUTPUT THAT PRINTS TO SCREEN!!#
ML_results = optim(par=params, fn=params_to_likelihood_v1, data.points=data.points, thetas_states_df=thetas_states_df, delay_val=0, printvals=TRUE, method="L-BFGS-B", lower=0.0, control=list(fnscale=-1))#
#
# Graphing the ML model#
# Take the learned parameters from "ML_results", put them#
# into a theta_states data.frame for simulation and plotting#
thetas_states_ML = thetas_states_df#
TF = thetas_states_ML == "free"#
thetas_states_ML[TF] = ML_results$par#
for (i in 1:ncol(thetas_states_ML))#
	{ thetas_states_ML[,i] = as.numeric(thetas_states_ML[,i]) }#
thetas_states_ML$time[2:length(thetas_states_ML$time)] = thetas_states_ML$time[2:length(thetas_states_ML$time)]#
# Plot the results#
trajectory = simulate_SIR_changes(thetas_states_df=thetas_states_ML, times=times)#
maxy = max(max(trajectory$I), max(data.points))#
xvals = c(trajectory$time, times)#
yvals = c(trajectory$I, data.points)#
plot(x=xvals, y=yvals, pch=".", col="white", xlim=c(0, max(trajectory$time)), ylim=c(0, maxy), xlab="Day", ylab="Number of individuals")#
lines(x=trajectory$time, y=trajectory$I, lwd=3, col="firebrick2")#
points(times, data.points, col="red", pch="+")#
legend(x="topleft", legend=c("Active COVID-19 case count", 'ML-fitted projection of "I" (Infected)'), lty=c("blank", "solid"), lwd=c(1,3), pch=c("+", "."), col=c("red","firebrick2"), cex=0.8)#
#
titletxt = paste0("ML fit, active cases from: ", country_name, "\nM6 (a 6-regime, 6 param model) max lnL = ", round(ML_results$value, 2))#
title(titletxt)#
#
# Save this model's parameters and log-likelihood#
thetas_states_ML_model6 = thetas_states_ML#
total_lnL_Model6 = ML_results$value
cat(c(total_lnL_Model1, total_lnL_Model2, total_lnL_Model3, total_lnL_Model4, total_lnL_Model5, total_lnL_Model6), sep="\n")#
#
# Print the I_ini to screen#
cat(c(thetas_states_ML_model1$I[2], thetas_states_ML_model2$I[2], thetas_states_ML_model3$I[2], thetas_states_ML_model4$I[2], thetas_states_ML_model5$I[2], thetas_states_ML_model6$I[2]), sep="\n")#
#
# Print the R0 to screen#
thetas_states_ML_model1$R0#
thetas_states_ML_model2$R0#
thetas_states_ML_model3$R0#
thetas_states_ML_model4$R0#
thetas_states_ML_model5$R0#
thetas_states_ML_model6$R0
1943-24
1942-17
library(devtools)#
devtools::install_github
? install_github
remove.packages("BioGeoBEARS")
library(devtools)#
devtools::install_github(repo="nmatzke/BioGeoBEARS", INSTALL_opts="--byte-compile")
remove.packages("BioGeoBEARS")
4/18
class(9)
install.packages("snow")
remove.packages("BioGeoBEARS")
library(devtools)
library(devtools)#
devtools::install_github(repo="nmatzke/BioGeoBEARS", INSTALL_opts="--byte-compile")
########################################################
# Edit tree to just NZ & nearby#
########################################################
#
library(ape)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
wd = "/drives/GDrive/__classes/BIOSCI395/lab/395lab/"#
#wd = "~/Downloads/395lab/"#
setwd(wd)#
#
trfn = "shared_tree_v5_burnin25_PPlimit0.0_MSCC_mean_heights.newick"#
tr = read.tree(trfn)#
#
geogfn = "Podocarpaceae_197_9areas_5Araucariaceae.data"#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Merge BCD (Africa-Asia-Sunda/Malesia) into D#
# Merge E+G (Papuasia + Australia)#
tdf = tipranges@df#
TF = tdf$B == TRUE#
tdf$D[TF] = 1#
#
TF = tdf$C == TRUE#
tdf$D[TF] = 1#
#
TF = tdf$E == TRUE#
tdf$G[TF] = 1#
#
# Remove B, C, E#
cols = c("A", "D", "F", "G", "H", "I")#
tdf2 = tdf[,cols]#
head(tdf2)#
max(rowSums(dfnums_to_numeric(tdf2)))#
# 2#
#
# Labels#
# A = South America#
# D = Africa-Asia-Sunda/Malesia#
# F = Fiji & Tonga#
# G = Sahul/Australia#
# H = New Caledonia#
# I = New Zealand#
#
numstates_from_numareas(numareas=6, maxareas=2, include_null_range=TRUE)#
# 22#
#
tipranges@df = tdf2#
#
save_tipranges_to_LagrangePHYLIP(tipranges, lgdata_fn="geog.data")
tmpfn = "geological_distances_v3_div100_stay_same.txt"#
distmats_list = read_distances_fn(inputs=NULL, distsfn=tmpfn)#
rows_to_keep_TF = c(TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE)#
#
new_distmats_list = subset_distmats(distmats_list, rows_to_keep_TF=rows_to_keep_TF, replace_NAs_with=0.0)
outfn = gsub(pattern=".txt", replacement="_subset.txt", x=tmpfn)#
write_distances_to_fn(new_distmats_list, outfn)#
moref(outfn)#
opd()
tmp = read_distances_fn(inputs=NULL, distsfn=outfn)
tmp
tmpfn = "modern_distances.txt"#
distmats_list = read_distances_fn(inputs=NULL, distsfn=tmpfn)#
rows_to_keep_TF = c(TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE)#
#
new_distmats_list = subset_distmats(distmats_list, rows_to_keep_TF=rows_to_keep_TF, replace_NAs_with=0.0)#
#
# Write distances matrix#
outfn = gsub(pattern=".txt", replacement="_subset.txt", x=tmpfn)#
write_distances_to_fn(new_distmats_list, outfn)#
moref(outfn)
tmpfn = "modern_distances.txt"#
distmats_list = read_distances_fn(inputs=NULL, distsfn=tmpfn)#
rows_to_keep_TF = c(TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE)#
#
new_distmats_list = subset_distmats(distmats_list, rows_to_keep_TF=rows_to_keep_TF, replace_NAs_with=0.0)#
#
# Write distances matrix#
outfn = gsub(pattern=".txt", replacement="_subset.txt", x=tmpfn)#
write_distances_to_fn(new_distmats_list, outfn)#
moref(outfn)
tmpfn = "geological_distances_v2_div100.txt"#
distmats_list = read_distances_fn(inputs=NULL, distsfn=tmpfn)#
rows_to_keep_TF = c(TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE)#
#
new_distmats_list = subset_distmats(distmats_list, rows_to_keep_TF=rows_to_keep_TF, replace_NAs_with=0.0)#
#
# Write distances matrix#
outfn = gsub(pattern=".txt", replacement="_subset.txt", x=tmpfn)#
write_distances_to_fn(new_distmats_list, outfn)#
moref(outfn)
tmpfn = "areas_allowed_NC37Ma.txt"#
distmats_list = read_distances_fn(inputs=NULL, distsfn=tmpfn)#
rows_to_keep_TF = c(TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE)#
#
new_distmats_list = subset_distmats(distmats_list, rows_to_keep_TF=rows_to_keep_TF, replace_NAs_with=0.0)#
#
# Write distances matrix#
outfn = gsub(pattern=".txt", replacement="_subset.txt", x=tmpfn)#
write_distances_to_fn(new_distmats_list, outfn)#
moref(outfn)
tmpfn = "areas_allowed_NC_NZ37Ma.txt"#
distmats_list = read_distances_fn(inputs=NULL, distsfn=tmpfn)#
rows_to_keep_TF = c(TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE)#
#
new_distmats_list = subset_distmats(distmats_list, rows_to_keep_TF=rows_to_keep_TF, replace_NAs_with=0.0)#
#
# Write distances matrix#
outfn = gsub(pattern=".txt", replacement="_subset.txt", x=tmpfn)#
write_distances_to_fn(new_distmats_list, outfn)#
moref(outfn)#
tmpfn = "areas_allowed_noNC52_37Ma.txt"#
distmats_list = read_distances_fn(inputs=NULL, distsfn=tmpfn)#
rows_to_keep_TF = c(TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE)#
#
new_distmats_list = subset_distmats(distmats_list, rows_to_keep_TF=rows_to_keep_TF, replace_NAs_with=0.0)#
#
# Write distances matrix#
outfn = gsub(pattern=".txt", replacement="_subset.txt", x=tmpfn)#
write_distances_to_fn(new_distmats_list, outfn)#
moref(outfn)
/drives/GDrive/__classes/BIOSCI395/lab/395lab/DEC+x_traits_models
library(optimx)         # You need to have some version of optimx available#
                        # as it is a BioGeoBEARS dependency; however, if you#
                        # don't want to use optimx, and use optim() (from R core) #
                        # you can set:#
                        # BioGeoBEARS_run_object$use_optimx = FALSE#
                        # ...everything should work either way -- NJM 2014-01-08#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
library(BioGeoBEARS)#
wd = "/drives/GDrive/__classes/BIOSCI395/lab/395lab/DEC+x_traits_models/"#
setwd(wd)#
########################################################
# Inference#
########################################################
max_range_size = 2#
########################################################
# Traits-only model -- 1 rate#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = 1#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog_1area.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = FALSE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
# Set up DEC model, but set all rates to 0 (data are 1 invariant area)#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = 0.0#
#
# Set up BAYAREALIKE model#
# No subset sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
# No vicariance#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","est"] = 0.0#
#
# No jump dispersal/founder-event speciation#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = 0.01#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = 0.01#
#
# Adjust linkage between parameters#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "1-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "1-j"#
#
# Only sympatric/range-copying (y) events allowed, and with #
# exact copying (both descendants always the same size as the ancestor)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","init"] = 0.9999#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","est"] = 0.9999#
tr = read.tree(BioGeoBEARS_run_object$trfn)#
#plot(tr); axisPhylo()#
#
geog_values = getranges_from_LagrangePHYLIP("trait.data")#
#
trait_fn = "trait.data"#
trait_values = getranges_from_LagrangePHYLIP(lgdata_fn=trait_fn)#
trait_values#
#
# Add the traits data and model#
BioGeoBEARS_run_object = add_trait_to_BioGeoBEARS_run_object(BioGeoBEARS_run_object, trait_fn=trait_fn)
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
########################################################
# Manual modifications of trait-based model#
########################################################
# Edit t12 and t21 rates#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "max"] = 1#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "type"] = "t12"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "max"] = 1#
#
# No multipliers on geog (set m1 and m2 to 1)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "desc"] = "trait-based dispersal rate multipliers m1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "desc"] = "trait-based dispersal rate multipliers m2"#
#
# Run this to check inputs. Read the error messages if you get them!#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)
runslow = TRUE#
resfn = "sim_traitsOnly_1rate_v1.Rdata"#
if (runslow)#
		{#
		res = bears_optim_run(BioGeoBEARS_run_object)#
		res    #
#
		save(res, file=resfn)#
		resTrait_1rate = res#
		} else {#
		# Loads to "res"#
		load(resfn)#
		resTrait_1rate = res#
		} # END if (runslow)
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = 1#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog_1area.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = FALSE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
# Set up DEC model, but set all rates to 0 (data are 1 invariant area)#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = 0.0#
#
# Set up BAYAREALIKE model#
# No subset sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
# No vicariance#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","est"] = 0.0#
#
# No jump dispersal/founder-event speciation#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = 0.01#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = 0.01#
#
# Adjust linkage between parameters#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "1-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "1-j"#
#
# Only sympatric/range-copying (y) events allowed, and with #
# exact copying (both descendants always the same size as the ancestor)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","init"] = 0.9999#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","est"] = 0.9999#
tr = read.tree(BioGeoBEARS_run_object$trfn)#
#plot(tr); axisPhylo()#
#
trait_fn = "trait.data"#
trait_values = getranges_from_LagrangePHYLIP(lgdata_fn=trait_fn)#
trait_values#
#
# Add the traits data and model#
BioGeoBEARS_run_object = add_trait_to_BioGeoBEARS_run_object(BioGeoBEARS_run_object, trait_fn=trait_fn)#
# Look at the params table#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
########################################################
# Manual modifications of trait-based model#
########################################################
# Edit t12 and t21 rates#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "max"] = 1#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "max"] = 1#
#
# No multipliers on geog (set m1 and m2 to 1)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "desc"] = "trait-based dispersal rate multipliers m1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "desc"] = "trait-based dispersal rate multipliers m2"#
#
# Run this to check inputs. Read the error messages if you get them!#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = TRUE#
resfn = "sim_traitsOnly_2rates_v1.Rdata"#
if (runslow)#
		{#
		res = bears_optim_run(BioGeoBEARS_run_object)#
		res    #
#
		save(res, file=resfn)#
		resTrait_2rates = res#
		} else {#
		# Loads to "res"#
		load(resfn)#
		resTrait_2rates = res#
		} # END if (runslow)
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
BioGeoBEARS_run_object$timesfn = "times_v2.txt"#
BioGeoBEARS_run_object$distsfn = "geological_distances_v3_div100_stay_same.txt"#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = TRUE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
#tr = read.tree(BioGeoBEARS_run_object$trfn)#
# Add x as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","init"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","est"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","max"] = 0#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
runslow = TRUE#
resfn = "DEC_inf.Rdata"#
if (runslow)#
	{#
	res = bears_optim_run(BioGeoBEARS_run_object)#
	res    #
#
	save(res, file=resfn)#
	resDEC = res#
	} else {#
	# Loads to "res"#
	load(resfn)#
	resDEC = res#
	}
library(ape)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
wd = "/drives/GDrive/__classes/BIOSCI395/lab/395lab/"#
#wd = "~/Downloads/395lab/"#
setwd(wd)#
#
trfn = "shared_tree_v5_burnin25_PPlimit0.0_MSCC_mean_heights.newick"#
tr = read.tree(trfn)#
#
geogfn = "Podocarpaceae_197_9areas_5Araucariaceae.data"#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Merge BCD (Africa-Asia-Sunda/Malesia) into D#
# Merge E+G (Papuasia + Australia)#
tdf = tipranges@df#
TF = tdf$B == TRUE#
tdf$D[TF] = 1#
#
TF = tdf$C == TRUE#
tdf$D[TF] = 1#
#
TF = tdf$E == TRUE#
tdf$G[TF] = 1
rowSums(tdf)
rowSums(tdf[,])
rowSums(dfnums_to_numeric(tdf))
cols = c("A", "D", "F", "G", "H", "I")#
tdf2 = tdf[,cols]#
head(tdf2)#
max(rowSums(dfnums_to_numeric(tdf2)))
rowSums(dfnums_to_numeric(tdf2)
)
tdf$B
library(ape)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
wd = "/drives/GDrive/__classes/BIOSCI395/lab/395lab/"#
#wd = "~/Downloads/395lab/"#
setwd(wd)#
#
trfn = "shared_tree_v5_burnin25_PPlimit0.0_MSCC_mean_heights.newick"#
tr = read.tree(trfn)#
#
geogfn = "Podocarpaceae_197_9areas_5Araucariaceae.data"#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Merge BCD (Africa-Asia-Sunda/Malesia) into D#
# Merge E+G (Papuasia + Australia)#
tdf = tipranges@df#
TF = tdf$B == "1"#
tdf$D[TF] = 1#
#
TF = tdf$C == "1"#
tdf$D[TF] = 1#
#
TF = tdf$E == "1"#
tdf$G[TF] = 1#
#
# Remove B, C, E#
cols = c("A", "D", "F", "G", "H", "I")#
tdf2 = tdf[,cols]#
head(tdf2)#
max(rowSums(dfnums_to_numeric(tdf2)))
min(rowSums(dfnums_to_numeric(tdf2)))
rowSums(dfnums_to_numeric(tdf2))
########################################################
# Run DEC (on geography only)#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
BioGeoBEARS_run_object$timesfn = "times_v2.txt"#
BioGeoBEARS_run_object$distsfn = "geological_distances_v3_div100_stay_same.txt"#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = TRUE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
#tr = read.tree(BioGeoBEARS_run_object$trfn)#
# Add x as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","init"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","est"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","max"] = 0#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)
########################################################
# Edit tree to just NZ & nearby#
########################################################
#
library(ape)#
library(rexpokit)#
library(cladoRcpp)#
library(BioGeoBEARS)#
#
wd = "/drives/GDrive/__classes/BIOSCI395/lab/395lab/"#
#wd = "~/Downloads/395lab/"#
setwd(wd)#
#
trfn = "shared_tree_v5_burnin25_PPlimit0.0_MSCC_mean_heights.newick"#
tr = read.tree(trfn)#
#
geogfn = "Podocarpaceae_197_9areas_5Araucariaceae.data"#
# Look at your geographic range data:#
tipranges = getranges_from_LagrangePHYLIP(lgdata_fn=geogfn)#
tipranges#
#
# Maximum range size observed:#
max(rowSums(dfnums_to_numeric(tipranges@df)))#
#
# Merge BCD (Africa-Asia-Sunda/Malesia) into D#
# Merge E+G (Papuasia + Australia)#
tdf = tipranges@df#
TF = tdf$B == "1"#
tdf$D[TF] = 1#
#
TF = tdf$C == "1"#
tdf$D[TF] = 1#
#
TF = tdf$E == "1"#
tdf$G[TF] = 1#
#
# Remove B, C, E#
cols = c("A", "D", "F", "G", "H", "I")#
tdf2 = tdf[,cols]#
head(tdf2)#
max(rowSums(dfnums_to_numeric(tdf2)))#
min(rowSums(dfnums_to_numeric(tdf2)))#
# 3, 1#
#
# Labels#
# A = South America#
# D = Africa-Asia-Sunda/Malesia#
# F = Fiji & Tonga#
# G = Sahul/Australia#
# H = New Caledonia#
# I = New Zealand#
#
numstates_from_numareas(numareas=6, maxareas=2, include_null_range=TRUE)#
# 22#
#
tipranges@df = tdf2#
#
save_tipranges_to_LagrangePHYLIP(tipranges, lgdata_fn="geog.data")
########################################################
# Example simulation and SSEsim#
########################################################
# Load the package (after installation, see above).#
library(optimx)         # You need to have some version of optimx available#
                        # as it is a BioGeoBEARS dependency; however, if you#
                        # don't want to use optimx, and use optim() (from R core) #
                        # you can set:#
                        # BioGeoBEARS_run_object$use_optimx = FALSE#
                        # ...everything should work either way -- NJM 2014-01-08#
library(FD)       # for FD::maxent() (make sure this is up-to-date)#
library(snow)     # (if you want to use multicore functionality; some systems/R versions prefer library(parallel), try either)#
library(parallel)#
library(BioGeoBEARS)#
wd = "/drives/GDrive/__classes/BIOSCI395/lab/395lab/DEC+x_traits_models/"#
setwd(wd)#
########################################################
# Inference#
########################################################
max_range_size = 2#
########################################################
# Traits-only model -- 1 rate#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = 1#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog_1area.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = FALSE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
# Set up DEC model, but set all rates to 0 (data are 1 invariant area)#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = 0.0#
#
# Set up BAYAREALIKE model#
# No subset sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
# No vicariance#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","est"] = 0.0#
#
# No jump dispersal/founder-event speciation#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = 0.01#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = 0.01#
#
# Adjust linkage between parameters#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "1-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "1-j"#
#
# Only sympatric/range-copying (y) events allowed, and with #
# exact copying (both descendants always the same size as the ancestor)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","init"] = 0.9999#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","est"] = 0.9999#
tr = read.tree(BioGeoBEARS_run_object$trfn)#
#plot(tr); axisPhylo()#
#
geog_values = getranges_from_LagrangePHYLIP("trait.data")#
#
trait_fn = "trait.data"#
trait_values = getranges_from_LagrangePHYLIP(lgdata_fn=trait_fn)#
trait_values#
#
# Add the traits data and model#
BioGeoBEARS_run_object = add_trait_to_BioGeoBEARS_run_object(BioGeoBEARS_run_object, trait_fn=trait_fn)#
# Look at the params table#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
########################################################
# Manual modifications of trait-based model#
########################################################
# Edit t12 and t21 rates#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "max"] = 1#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "type"] = "t12"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "max"] = 1#
#
# No multipliers on geog (set m1 and m2 to 1)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "desc"] = "trait-based dispersal rate multipliers m1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "desc"] = "trait-based dispersal rate multipliers m2"#
#
# Run this to check inputs. Read the error messages if you get them!#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = FALSE#
resfn = "sim_traitsOnly_1rate_v1.Rdata"#
if (runslow)#
		{#
		res = bears_optim_run(BioGeoBEARS_run_object)#
		res    #
#
		save(res, file=resfn)#
		resTrait_1rate = res#
		} else {#
		# Loads to "res"#
		load(resfn)#
		resTrait_1rate = res#
		} # END if (runslow)#
########################################################
# Traits-only model -- 2 rates#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = 1#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog_1area.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = FALSE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
# Set up DEC model, but set all rates to 0 (data are 1 invariant area)#
# (nothing to do; defaults)#
#
# Look at the BioGeoBEARS_run_object; it's just a list of settings etc.#
BioGeoBEARS_run_object#
#
# This contains the model object#
BioGeoBEARS_run_object$BioGeoBEARS_model_object#
#
# This table contains the parameters of the model #
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["a","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["d","est"] = 0.0#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["e","est"] = 0.0#
#
# Set up BAYAREALIKE model#
# No subset sympatry#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["s","est"] = 0.0#
#
# No vicariance#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","init"] = 0.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["v","est"] = 0.0#
#
# No jump dispersal/founder-event speciation#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = 0.01#
# BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = 0.01#
#
# Adjust linkage between parameters#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ysv","type"] = "1-j"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["ys","type"] = "ysv*1/1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["y","type"] = "1-j"#
#
# Only sympatric/range-copying (y) events allowed, and with #
# exact copying (both descendants always the same size as the ancestor)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","init"] = 0.9999#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["mx01y","est"] = 0.9999#
tr = read.tree(BioGeoBEARS_run_object$trfn)#
#plot(tr); axisPhylo()#
#
trait_fn = "trait.data"#
trait_values = getranges_from_LagrangePHYLIP(lgdata_fn=trait_fn)#
trait_values#
#
# Add the traits data and model#
BioGeoBEARS_run_object = add_trait_to_BioGeoBEARS_run_object(BioGeoBEARS_run_object, trait_fn=trait_fn)#
# Look at the params table#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table#
#
########################################################
# Manual modifications of trait-based model#
########################################################
# Edit t12 and t21 rates#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t12", "max"] = 1#
#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "init"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "est"] = 0.001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "min"] = 0.00001#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["t21", "max"] = 1#
#
# No multipliers on geog (set m1 and m2 to 1)#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "type"] = "fixed"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "init"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "est"] = 1.0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m1", "desc"] = "trait-based dispersal rate multipliers m1"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["m2", "desc"] = "trait-based dispersal rate multipliers m2"#
#
# Run this to check inputs. Read the error messages if you get them!#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
# For a slow analysis, run once, then set runslow=FALSE to just #
# load the saved result.#
runslow = FALSE#
resfn = "sim_traitsOnly_2rates_v1.Rdata"#
if (runslow)#
		{#
		res = bears_optim_run(BioGeoBEARS_run_object)#
		res    #
#
		save(res, file=resfn)#
		resTrait_2rates = res#
		} else {#
		# Loads to "res"#
		load(resfn)#
		resTrait_2rates = res#
		} # END if (runslow)#
########################################################
# Run DEC (on geography only)#
########################################################
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
BioGeoBEARS_run_object$timesfn = "times_v2.txt"#
BioGeoBEARS_run_object$distsfn = "geological_distances_v3_div100_stay_same.txt"#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = TRUE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
#tr = read.tree(BioGeoBEARS_run_object$trfn)#
# Add x as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","init"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","est"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","max"] = 0#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
#BioGeoBEARS_run_object$timesfn = "times_v2.txt"#
BioGeoBEARS_run_object$distsfn = "modern_distances_subset.txt"#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = TRUE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
#tr = read.tree(BioGeoBEARS_run_object$trfn)#
# Add x as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","init"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","est"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","max"] = 0#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
runslow = TRUE#
resfn = "DEC_inf.Rdata"#
if (runslow)#
	{#
	res = bears_optim_run(BioGeoBEARS_run_object)#
	res    #
#
	save(res, file=resfn)#
	resDEC = res#
	} else {#
	# Loads to "res"#
	load(resfn)#
	resDEC = res#
	}
max_range_size = 3
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
#BioGeoBEARS_run_object$timesfn = "times_v2.txt"#
BioGeoBEARS_run_object$distsfn = "modern_distances_subset.txt"#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = TRUE  # works with kexpmv, but compare to dense,#
# time-stratify to break up long branches if you see major differences in lnL#
#
#tr = read.tree(BioGeoBEARS_run_object$trfn)#
# Add x as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","init"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","est"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","max"] = 0#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
runslow = TRUE#
resfn = "DEC_inf.Rdata"#
if (runslow)#
	{#
	res = bears_optim_run(BioGeoBEARS_run_object)#
	res    #
#
	save(res, file=resfn)#
	resDEC = res#
	} else {#
	# Loads to "res"#
	load(resfn)#
	resDEC = res#
	}
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
#BioGeoBEARS_run_object$timesfn = "times_v2.txt"#
BioGeoBEARS_run_object$distsfn = "modern_distances_subset.txt"#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = FALSE#
#
#tr = read.tree(BioGeoBEARS_run_object$trfn)#
# Add x as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","init"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","est"] = 0#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","max"] = 0#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)#
#
runslow = TRUE#
resfn = "DEC_inf.Rdata"#
if (runslow)#
	{#
	res = bears_optim_run(BioGeoBEARS_run_object)#
	res    #
#
	save(res, file=resfn)#
	resDEC = res#
	} else {#
	# Loads to "res"#
	load(resfn)#
	resDEC = res#
	}
BioGeoBEARS_run_object = define_BioGeoBEARS_run()#
BioGeoBEARS_run_object$print_optim = TRUE#
BioGeoBEARS_run_object$calc_ancprobs=TRUE        # get ancestral states from optim run#
BioGeoBEARS_run_object$max_range_size = max_range_size#
BioGeoBEARS_run_object$num_cores_to_use = 1#
BioGeoBEARS_run_object$use_optimx="GenSA"#
BioGeoBEARS_run_object$speedup=TRUE#
BioGeoBEARS_run_object$geogfn = "geog.data"#
BioGeoBEARS_run_object$trfn = "tree.newick"#
#BioGeoBEARS_run_object$timesfn = "times_v2.txt"#
BioGeoBEARS_run_object$distsfn = "modern_distances_subset.txt"#
#BioGeoBEARS_run_object = section_the_tree(inputs=BioGeoBEARS_run_object, make_master_table=TRUE, plot_pieces=FALSE)#
BioGeoBEARS_run_object = readfiles_BioGeoBEARS_run(BioGeoBEARS_run_object)#
BioGeoBEARS_run_object$return_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_TTL_loglike_from_condlikes_table = TRUE#
BioGeoBEARS_run_object$calc_ancprobs = TRUE#
BioGeoBEARS_run_object$on_NaN_error = -1000000#
BioGeoBEARS_run_object$force_sparse = FALSE#
#
#tr = read.tree(BioGeoBEARS_run_object$trfn)#
#
dstart = resDEC$outputs@params_table["d","est"]#
estart = resDEC$outputs@params_table["e","est"]#
jstart = 0.0001#
xstart = resDEC$outputs@params_table["x","est"]#
#
# Add j as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","init"] = jstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["j","est"] = jstart#
#
# Add x as a free parameter#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","type"] = "free"#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","init"] = xstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","est"] = xstart#
BioGeoBEARS_run_object$BioGeoBEARS_model_object@params_table["x","max"] = 0#
#
BioGeoBEARS_run_object = fix_BioGeoBEARS_params_minmax(BioGeoBEARS_run_object)#
check_BioGeoBEARS_run(BioGeoBEARS_run_object)
print("Printing warnings: 'warnings()':")#
print(warnings())#
#
runslow = TRUE#
resfn = "DECj_inf.Rdata"#
if (runslow)#
	{#
	res = bears_optim_run(BioGeoBEARS_run_object)#
	res    #
#
	save(res, file=resfn)#
	resDECj = res#
	} else {#
	# Loads to "res"#
	load(resfn)#
	resDECj = res#
	}
